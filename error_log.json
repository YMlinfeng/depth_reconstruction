{"message": {"message": "RuntimeError: mat1 and mat2 shapes cannot be multiplied (120000x4 and 64x1024)", "extraInfo": {"py_callstack": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.9/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 346, in wrapper\n    return f(*args, **kwargs)\n  File \"/mnt/bn/occupancy3d/workspace/mzj/mp_pretrain/train.py\", line 423, in main\n    train_vqvae(args, model, vqvae, train_loader, val_loader, device)\n  File \"/mnt/bn/occupancy3d/workspace/mzj/mp_pretrain/train.py\", line 165, in train_vqvae\n    vqvae_out = vqvae(voxel)   # \u5305\u542b 'logits', 'embed_loss'\n  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/mnt/bn/occupancy3d/workspace/mzj/mp_pretrain/vqvae/vae_2d_resnet.py\", line 1173, in forward\n    z = self.forward_encoder(x) # z.shape: torch.Size([1, 4, 30, 50, 1])\n  File \"/mnt/bn/occupancy3d/workspace/mzj/mp_pretrain/vqvae/vae_2d_resnet.py\", line 1156, in forward_encoder\n    x = self.embedder(x)\n  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: mat1 and mat2 shapes cannot be multiplied (120000x4 and 64x1024)\n", "timestamp": "1746639423"}}}
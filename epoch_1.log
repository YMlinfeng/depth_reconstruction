
ğŸ” æ­£åœ¨è§£ææ–‡ä»¶: /mnt/bn/occupancy3d/workspace/lzy/Occ3d/work_dirs/pretrainv0.7_2dvqvaelargefewfewchannels/epoch_1.pth

ğŸ“Œ æ£€æµ‹åˆ°å­—å…¸ç±»å‹æ•°æ®ï¼Œå¯èƒ½æ˜¯ `state_dict` æˆ–è‡ªå®šä¹‰æ•°æ®
ğŸ”¹ å¯èƒ½æ˜¯ `state_dict`ï¼Œå°è¯•è§£æ `state_dict`

ğŸ“œ **è§£æå†…å®¹:**

ğŸ”¹ `pts_bbox_head.img_view_transformer.dx`: shape=torch.Size([3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.bx`: shape=torch.Size([3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.nx`: shape=torch.Size([3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.reduce_conv.0.weight`: shape=torch.Size([384, 384, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.reduce_conv.0.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.reduce_conv.1.weight`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.reduce_conv.1.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.reduce_conv.1.running_mean`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.reduce_conv.1.running_var`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.reduce_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.context_conv.weight`: shape=torch.Size([128, 384, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.context_conv.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.bn.weight`: shape=torch.Size([27]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.bn.bias`: shape=torch.Size([27]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.bn.running_mean`: shape=torch.Size([27]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.bn.running_var`: shape=torch.Size([27]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_mlp.fc1.weight`: shape=torch.Size([384, 27]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_mlp.fc1.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_mlp.fc2.weight`: shape=torch.Size([384, 384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_mlp.fc2.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_se.conv_reduce.weight`: shape=torch.Size([384, 384, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_se.conv_reduce.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_se.conv_expand.weight`: shape=torch.Size([384, 384, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_se.conv_expand.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.context_mlp.fc1.weight`: shape=torch.Size([384, 27]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.context_mlp.fc1.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.context_mlp.fc2.weight`: shape=torch.Size([384, 384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.context_mlp.fc2.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.context_se.conv_reduce.weight`: shape=torch.Size([384, 384, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.context_se.conv_reduce.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.context_se.conv_expand.weight`: shape=torch.Size([384, 384, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.context_se.conv_expand.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.0.conv1.weight`: shape=torch.Size([384, 384, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.0.bn1.weight`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.0.bn1.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.0.bn1.running_mean`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.0.bn1.running_var`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.0.bn1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.0.conv2.weight`: shape=torch.Size([384, 384, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.0.bn2.weight`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.0.bn2.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.0.bn2.running_mean`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.0.bn2.running_var`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.0.bn2.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.1.conv1.weight`: shape=torch.Size([384, 384, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.1.bn1.weight`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.1.bn1.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.1.bn1.running_mean`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.1.bn1.running_var`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.1.bn1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.1.conv2.weight`: shape=torch.Size([384, 384, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.1.bn2.weight`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.1.bn2.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.1.bn2.running_mean`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.1.bn2.running_var`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.1.bn2.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.2.conv1.weight`: shape=torch.Size([384, 384, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.2.bn1.weight`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.2.bn1.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.2.bn1.running_mean`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.2.bn1.running_var`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.2.bn1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.2.conv2.weight`: shape=torch.Size([384, 384, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.2.bn2.weight`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.2.bn2.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.2.bn2.running_mean`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.2.bn2.running_var`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.2.bn2.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.3.aspp1.atrous_conv.weight`: shape=torch.Size([384, 384, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.3.aspp1.bn.weight`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.3.aspp1.bn.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.3.aspp1.bn.running_mean`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.3.aspp1.bn.running_var`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.3.aspp1.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.3.aspp2.atrous_conv.weight`: shape=torch.Size([384, 384, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.3.aspp2.bn.weight`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.3.aspp2.bn.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.3.aspp2.bn.running_mean`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.3.aspp2.bn.running_var`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.3.aspp2.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.3.aspp3.atrous_conv.weight`: shape=torch.Size([384, 384, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.3.aspp3.bn.weight`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.3.aspp3.bn.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.3.aspp3.bn.running_mean`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.3.aspp3.bn.running_var`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.3.aspp3.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.3.aspp4.atrous_conv.weight`: shape=torch.Size([384, 384, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.3.aspp4.bn.weight`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.3.aspp4.bn.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.3.aspp4.bn.running_mean`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.3.aspp4.bn.running_var`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.3.aspp4.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.3.global_avg_pool.1.weight`: shape=torch.Size([384, 384, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.3.global_avg_pool.2.weight`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.3.global_avg_pool.2.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.3.global_avg_pool.2.running_mean`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.3.global_avg_pool.2.running_var`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.3.global_avg_pool.2.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.3.conv1.weight`: shape=torch.Size([384, 1920, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.3.bn1.weight`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.3.bn1.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.3.bn1.running_mean`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.3.bn1.running_var`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.3.bn1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.4.weight`: shape=torch.Size([199, 384, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_view_transformer.depth_net.depth_conv.4.bias`: shape=torch.Size([199]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.combine_xy.weight`: shape=torch.Size([1, 128, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.combine_xy.bias`: shape=torch.Size([1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.combine_yz.weight`: shape=torch.Size([1, 128, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.combine_yz.bias`: shape=torch.Size([1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.combine_xz.weight`: shape=torch.Size([1, 128, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.combine_xz.bias`: shape=torch.Size([1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.0.input_conv.0.weight`: shape=torch.Size([128, 128, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.0.input_conv.1.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.0.input_conv.1.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.0.input_conv.1.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.0.input_conv.1.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.0.input_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.0.bev_encoder.norm1.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.0.bev_encoder.norm1.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.0.bev_encoder.attn.w_msa.relative_position_bias_table`: shape=torch.Size([169, 4]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.0.bev_encoder.attn.w_msa.relative_position_index`: shape=torch.Size([49, 49]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.0.bev_encoder.attn.w_msa.qkv.weight`: shape=torch.Size([384, 128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.0.bev_encoder.attn.w_msa.qkv.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.0.bev_encoder.attn.w_msa.proj.weight`: shape=torch.Size([128, 128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.0.bev_encoder.attn.w_msa.proj.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.0.bev_encoder.norm2.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.0.bev_encoder.norm2.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.0.bev_encoder.ffn.layers.0.0.weight`: shape=torch.Size([128, 128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.0.bev_encoder.ffn.layers.0.0.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.0.bev_encoder.ffn.layers.1.weight`: shape=torch.Size([128, 128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.0.bev_encoder.ffn.layers.1.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.0.aspp.input_conv.0.weight`: shape=torch.Size([32, 128, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.0.aspp.input_conv.1.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.0.aspp.input_conv.1.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.0.aspp.input_conv.1.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.0.aspp.input_conv.1.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.0.aspp.input_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.0.aspp.aspp.aspp1.atrous_conv.weight`: shape=torch.Size([32, 32, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.0.aspp.aspp.aspp1.bn.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.0.aspp.aspp.aspp1.bn.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.0.aspp.aspp.aspp1.bn.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.0.aspp.aspp.aspp1.bn.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.0.aspp.aspp.aspp1.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.0.aspp.aspp.aspp2.atrous_conv.weight`: shape=torch.Size([32, 32, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.0.aspp.aspp.aspp2.bn.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.0.aspp.aspp.aspp2.bn.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.0.aspp.aspp.aspp2.bn.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.0.aspp.aspp.aspp2.bn.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.0.aspp.aspp.aspp2.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.0.aspp.aspp.aspp3.atrous_conv.weight`: shape=torch.Size([32, 32, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.0.aspp.aspp.aspp3.bn.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.0.aspp.aspp.aspp3.bn.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.0.aspp.aspp.aspp3.bn.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.0.aspp.aspp.aspp3.bn.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.0.aspp.aspp.aspp3.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.0.aspp.aspp.aspp4.atrous_conv.weight`: shape=torch.Size([32, 32, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.0.aspp.aspp.aspp4.bn.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.0.aspp.aspp.aspp4.bn.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.0.aspp.aspp.aspp4.bn.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.0.aspp.aspp.aspp4.bn.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.0.aspp.aspp.aspp4.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.0.aspp.aspp.global_avg_pool.1.weight`: shape=torch.Size([32, 32, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.0.aspp.aspp.global_avg_pool.2.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.0.aspp.aspp.global_avg_pool.2.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.0.aspp.aspp.global_avg_pool.2.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.0.aspp.aspp.global_avg_pool.2.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.0.aspp.aspp.global_avg_pool.2.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.0.aspp.aspp.conv1.weight`: shape=torch.Size([32, 160, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.0.aspp.aspp.bn1.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.0.aspp.aspp.bn1.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.0.aspp.aspp.bn1.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.0.aspp.aspp.bn1.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.0.aspp.aspp.bn1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.0.aspp.output_conv.0.weight`: shape=torch.Size([128, 32, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.0.aspp.output_conv.1.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.0.aspp.output_conv.1.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.0.aspp.output_conv.1.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.0.aspp.output_conv.1.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.0.aspp.output_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.0.combine_coeff.weight`: shape=torch.Size([1, 128, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.0.combine_coeff.bias`: shape=torch.Size([1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.1.input_conv.0.weight`: shape=torch.Size([128, 128, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.1.input_conv.1.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.1.input_conv.1.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.1.input_conv.1.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.1.input_conv.1.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.1.input_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.1.bev_encoder.norm1.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.1.bev_encoder.norm1.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.1.bev_encoder.attn.w_msa.relative_position_bias_table`: shape=torch.Size([169, 4]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.1.bev_encoder.attn.w_msa.relative_position_index`: shape=torch.Size([49, 49]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.1.bev_encoder.attn.w_msa.qkv.weight`: shape=torch.Size([384, 128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.1.bev_encoder.attn.w_msa.qkv.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.1.bev_encoder.attn.w_msa.proj.weight`: shape=torch.Size([128, 128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.1.bev_encoder.attn.w_msa.proj.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.1.bev_encoder.norm2.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.1.bev_encoder.norm2.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.1.bev_encoder.ffn.layers.0.0.weight`: shape=torch.Size([128, 128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.1.bev_encoder.ffn.layers.0.0.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.1.bev_encoder.ffn.layers.1.weight`: shape=torch.Size([128, 128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.1.bev_encoder.ffn.layers.1.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.1.aspp.input_conv.0.weight`: shape=torch.Size([32, 128, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.1.aspp.input_conv.1.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.1.aspp.input_conv.1.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.1.aspp.input_conv.1.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.1.aspp.input_conv.1.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.1.aspp.input_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.1.aspp.aspp.aspp1.atrous_conv.weight`: shape=torch.Size([32, 32, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.1.aspp.aspp.aspp1.bn.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.1.aspp.aspp.aspp1.bn.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.1.aspp.aspp.aspp1.bn.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.1.aspp.aspp.aspp1.bn.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.1.aspp.aspp.aspp1.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.1.aspp.aspp.aspp2.atrous_conv.weight`: shape=torch.Size([32, 32, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.1.aspp.aspp.aspp2.bn.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.1.aspp.aspp.aspp2.bn.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.1.aspp.aspp.aspp2.bn.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.1.aspp.aspp.aspp2.bn.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.1.aspp.aspp.aspp2.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.1.aspp.aspp.aspp3.atrous_conv.weight`: shape=torch.Size([32, 32, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.1.aspp.aspp.aspp3.bn.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.1.aspp.aspp.aspp3.bn.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.1.aspp.aspp.aspp3.bn.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.1.aspp.aspp.aspp3.bn.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.1.aspp.aspp.aspp3.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.1.aspp.aspp.aspp4.atrous_conv.weight`: shape=torch.Size([32, 32, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.1.aspp.aspp.aspp4.bn.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.1.aspp.aspp.aspp4.bn.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.1.aspp.aspp.aspp4.bn.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.1.aspp.aspp.aspp4.bn.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.1.aspp.aspp.aspp4.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.1.aspp.aspp.global_avg_pool.1.weight`: shape=torch.Size([32, 32, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.1.aspp.aspp.global_avg_pool.2.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.1.aspp.aspp.global_avg_pool.2.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.1.aspp.aspp.global_avg_pool.2.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.1.aspp.aspp.global_avg_pool.2.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.1.aspp.aspp.global_avg_pool.2.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.1.aspp.aspp.conv1.weight`: shape=torch.Size([32, 160, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.1.aspp.aspp.bn1.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.1.aspp.aspp.bn1.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.1.aspp.aspp.bn1.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.1.aspp.aspp.bn1.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.1.aspp.aspp.bn1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.1.aspp.output_conv.0.weight`: shape=torch.Size([128, 32, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.1.aspp.output_conv.1.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.1.aspp.output_conv.1.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.1.aspp.output_conv.1.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.1.aspp.output_conv.1.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.1.aspp.output_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.1.combine_coeff.weight`: shape=torch.Size([1, 128, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.0.1.combine_coeff.bias`: shape=torch.Size([1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.downsample.0.weight`: shape=torch.Size([128, 128, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.downsample.1.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.downsample.1.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.downsample.1.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.downsample.1.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.downsample.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.input_conv.0.weight`: shape=torch.Size([128, 128, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.input_conv.1.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.input_conv.1.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.input_conv.1.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.input_conv.1.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.input_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.bev_encoder.norm1.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.bev_encoder.norm1.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.bev_encoder.attn.w_msa.relative_position_bias_table`: shape=torch.Size([169, 4]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.bev_encoder.attn.w_msa.relative_position_index`: shape=torch.Size([49, 49]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.bev_encoder.attn.w_msa.qkv.weight`: shape=torch.Size([384, 128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.bev_encoder.attn.w_msa.qkv.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.bev_encoder.attn.w_msa.proj.weight`: shape=torch.Size([128, 128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.bev_encoder.attn.w_msa.proj.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.bev_encoder.norm2.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.bev_encoder.norm2.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.bev_encoder.ffn.layers.0.0.weight`: shape=torch.Size([128, 128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.bev_encoder.ffn.layers.0.0.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.bev_encoder.ffn.layers.1.weight`: shape=torch.Size([128, 128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.bev_encoder.ffn.layers.1.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.aspp.input_conv.0.weight`: shape=torch.Size([32, 128, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.aspp.input_conv.1.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.aspp.input_conv.1.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.aspp.input_conv.1.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.aspp.input_conv.1.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.aspp.input_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.aspp.aspp.aspp1.atrous_conv.weight`: shape=torch.Size([32, 32, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.aspp.aspp.aspp1.bn.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.aspp.aspp.aspp1.bn.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.aspp.aspp.aspp1.bn.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.aspp.aspp.aspp1.bn.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.aspp.aspp.aspp1.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.aspp.aspp.aspp2.atrous_conv.weight`: shape=torch.Size([32, 32, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.aspp.aspp.aspp2.bn.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.aspp.aspp.aspp2.bn.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.aspp.aspp.aspp2.bn.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.aspp.aspp.aspp2.bn.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.aspp.aspp.aspp2.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.aspp.aspp.aspp3.atrous_conv.weight`: shape=torch.Size([32, 32, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.aspp.aspp.aspp3.bn.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.aspp.aspp.aspp3.bn.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.aspp.aspp.aspp3.bn.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.aspp.aspp.aspp3.bn.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.aspp.aspp.aspp3.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.aspp.aspp.aspp4.atrous_conv.weight`: shape=torch.Size([32, 32, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.aspp.aspp.aspp4.bn.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.aspp.aspp.aspp4.bn.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.aspp.aspp.aspp4.bn.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.aspp.aspp.aspp4.bn.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.aspp.aspp.aspp4.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.aspp.aspp.global_avg_pool.1.weight`: shape=torch.Size([32, 32, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.aspp.aspp.global_avg_pool.2.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.aspp.aspp.global_avg_pool.2.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.aspp.aspp.global_avg_pool.2.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.aspp.aspp.global_avg_pool.2.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.aspp.aspp.global_avg_pool.2.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.aspp.aspp.conv1.weight`: shape=torch.Size([32, 160, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.aspp.aspp.bn1.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.aspp.aspp.bn1.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.aspp.aspp.bn1.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.aspp.aspp.bn1.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.aspp.aspp.bn1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.aspp.output_conv.0.weight`: shape=torch.Size([128, 32, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.aspp.output_conv.1.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.aspp.output_conv.1.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.aspp.output_conv.1.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.aspp.output_conv.1.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.aspp.output_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.combine_coeff.weight`: shape=torch.Size([1, 128, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.0.combine_coeff.bias`: shape=torch.Size([1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.1.input_conv.0.weight`: shape=torch.Size([128, 128, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.1.input_conv.1.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.1.input_conv.1.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.1.input_conv.1.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.1.input_conv.1.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.1.input_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.1.bev_encoder.norm1.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.1.bev_encoder.norm1.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.1.bev_encoder.attn.w_msa.relative_position_bias_table`: shape=torch.Size([169, 4]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.1.bev_encoder.attn.w_msa.relative_position_index`: shape=torch.Size([49, 49]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.1.bev_encoder.attn.w_msa.qkv.weight`: shape=torch.Size([384, 128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.1.bev_encoder.attn.w_msa.qkv.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.1.bev_encoder.attn.w_msa.proj.weight`: shape=torch.Size([128, 128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.1.bev_encoder.attn.w_msa.proj.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.1.bev_encoder.norm2.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.1.bev_encoder.norm2.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.1.bev_encoder.ffn.layers.0.0.weight`: shape=torch.Size([128, 128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.1.bev_encoder.ffn.layers.0.0.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.1.bev_encoder.ffn.layers.1.weight`: shape=torch.Size([128, 128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.1.bev_encoder.ffn.layers.1.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.1.aspp.input_conv.0.weight`: shape=torch.Size([32, 128, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.1.aspp.input_conv.1.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.1.aspp.input_conv.1.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.1.aspp.input_conv.1.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.1.aspp.input_conv.1.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.1.aspp.input_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.1.aspp.aspp.aspp1.atrous_conv.weight`: shape=torch.Size([32, 32, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.1.aspp.aspp.aspp1.bn.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.1.aspp.aspp.aspp1.bn.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.1.aspp.aspp.aspp1.bn.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.1.aspp.aspp.aspp1.bn.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.1.aspp.aspp.aspp1.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.1.aspp.aspp.aspp2.atrous_conv.weight`: shape=torch.Size([32, 32, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.1.aspp.aspp.aspp2.bn.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.1.aspp.aspp.aspp2.bn.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.1.aspp.aspp.aspp2.bn.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.1.aspp.aspp.aspp2.bn.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.1.aspp.aspp.aspp2.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.1.aspp.aspp.aspp3.atrous_conv.weight`: shape=torch.Size([32, 32, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.1.aspp.aspp.aspp3.bn.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.1.aspp.aspp.aspp3.bn.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.1.aspp.aspp.aspp3.bn.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.1.aspp.aspp.aspp3.bn.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.1.aspp.aspp.aspp3.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.1.aspp.aspp.aspp4.atrous_conv.weight`: shape=torch.Size([32, 32, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.1.aspp.aspp.aspp4.bn.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.1.aspp.aspp.aspp4.bn.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.1.aspp.aspp.aspp4.bn.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.1.aspp.aspp.aspp4.bn.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.1.aspp.aspp.aspp4.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.1.aspp.aspp.global_avg_pool.1.weight`: shape=torch.Size([32, 32, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.1.aspp.aspp.global_avg_pool.2.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.1.aspp.aspp.global_avg_pool.2.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.1.aspp.aspp.global_avg_pool.2.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.1.aspp.aspp.global_avg_pool.2.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.1.aspp.aspp.global_avg_pool.2.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.1.aspp.aspp.conv1.weight`: shape=torch.Size([32, 160, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.1.aspp.aspp.bn1.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.1.aspp.aspp.bn1.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.1.aspp.aspp.bn1.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.1.aspp.aspp.bn1.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.1.aspp.aspp.bn1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.1.aspp.output_conv.0.weight`: shape=torch.Size([128, 32, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.1.aspp.output_conv.1.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.1.aspp.output_conv.1.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.1.aspp.output_conv.1.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.1.aspp.output_conv.1.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.1.aspp.output_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.1.combine_coeff.weight`: shape=torch.Size([1, 128, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.1.1.combine_coeff.bias`: shape=torch.Size([1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.downsample.0.weight`: shape=torch.Size([256, 128, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.downsample.1.weight`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.downsample.1.bias`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.downsample.1.running_mean`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.downsample.1.running_var`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.downsample.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.input_conv.0.weight`: shape=torch.Size([256, 128, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.input_conv.1.weight`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.input_conv.1.bias`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.input_conv.1.running_mean`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.input_conv.1.running_var`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.input_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.bev_encoder.norm1.weight`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.bev_encoder.norm1.bias`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.bev_encoder.attn.w_msa.relative_position_bias_table`: shape=torch.Size([169, 8]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.bev_encoder.attn.w_msa.relative_position_index`: shape=torch.Size([49, 49]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.bev_encoder.attn.w_msa.qkv.weight`: shape=torch.Size([768, 256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.bev_encoder.attn.w_msa.qkv.bias`: shape=torch.Size([768]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.bev_encoder.attn.w_msa.proj.weight`: shape=torch.Size([256, 256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.bev_encoder.attn.w_msa.proj.bias`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.bev_encoder.norm2.weight`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.bev_encoder.norm2.bias`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.bev_encoder.ffn.layers.0.0.weight`: shape=torch.Size([256, 256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.bev_encoder.ffn.layers.0.0.bias`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.bev_encoder.ffn.layers.1.weight`: shape=torch.Size([256, 256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.bev_encoder.ffn.layers.1.bias`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.aspp.input_conv.0.weight`: shape=torch.Size([64, 256, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.aspp.input_conv.1.weight`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.aspp.input_conv.1.bias`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.aspp.input_conv.1.running_mean`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.aspp.input_conv.1.running_var`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.aspp.input_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.aspp.aspp.aspp1.atrous_conv.weight`: shape=torch.Size([64, 64, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.aspp.aspp.aspp1.bn.weight`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.aspp.aspp.aspp1.bn.bias`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.aspp.aspp.aspp1.bn.running_mean`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.aspp.aspp.aspp1.bn.running_var`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.aspp.aspp.aspp1.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.aspp.aspp.aspp2.atrous_conv.weight`: shape=torch.Size([64, 64, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.aspp.aspp.aspp2.bn.weight`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.aspp.aspp.aspp2.bn.bias`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.aspp.aspp.aspp2.bn.running_mean`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.aspp.aspp.aspp2.bn.running_var`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.aspp.aspp.aspp2.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.aspp.aspp.aspp3.atrous_conv.weight`: shape=torch.Size([64, 64, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.aspp.aspp.aspp3.bn.weight`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.aspp.aspp.aspp3.bn.bias`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.aspp.aspp.aspp3.bn.running_mean`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.aspp.aspp.aspp3.bn.running_var`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.aspp.aspp.aspp3.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.aspp.aspp.aspp4.atrous_conv.weight`: shape=torch.Size([64, 64, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.aspp.aspp.aspp4.bn.weight`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.aspp.aspp.aspp4.bn.bias`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.aspp.aspp.aspp4.bn.running_mean`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.aspp.aspp.aspp4.bn.running_var`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.aspp.aspp.aspp4.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.aspp.aspp.global_avg_pool.1.weight`: shape=torch.Size([64, 64, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.aspp.aspp.global_avg_pool.2.weight`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.aspp.aspp.global_avg_pool.2.bias`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.aspp.aspp.global_avg_pool.2.running_mean`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.aspp.aspp.global_avg_pool.2.running_var`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.aspp.aspp.global_avg_pool.2.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.aspp.aspp.conv1.weight`: shape=torch.Size([64, 320, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.aspp.aspp.bn1.weight`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.aspp.aspp.bn1.bias`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.aspp.aspp.bn1.running_mean`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.aspp.aspp.bn1.running_var`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.aspp.aspp.bn1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.aspp.output_conv.0.weight`: shape=torch.Size([256, 64, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.aspp.output_conv.1.weight`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.aspp.output_conv.1.bias`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.aspp.output_conv.1.running_mean`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.aspp.output_conv.1.running_var`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.aspp.output_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.combine_coeff.weight`: shape=torch.Size([1, 256, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.0.combine_coeff.bias`: shape=torch.Size([1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.1.input_conv.0.weight`: shape=torch.Size([256, 256, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.1.input_conv.1.weight`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.1.input_conv.1.bias`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.1.input_conv.1.running_mean`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.1.input_conv.1.running_var`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.1.input_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.1.bev_encoder.norm1.weight`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.1.bev_encoder.norm1.bias`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.1.bev_encoder.attn.w_msa.relative_position_bias_table`: shape=torch.Size([169, 8]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.1.bev_encoder.attn.w_msa.relative_position_index`: shape=torch.Size([49, 49]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.1.bev_encoder.attn.w_msa.qkv.weight`: shape=torch.Size([768, 256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.1.bev_encoder.attn.w_msa.qkv.bias`: shape=torch.Size([768]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.1.bev_encoder.attn.w_msa.proj.weight`: shape=torch.Size([256, 256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.1.bev_encoder.attn.w_msa.proj.bias`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.1.bev_encoder.norm2.weight`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.1.bev_encoder.norm2.bias`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.1.bev_encoder.ffn.layers.0.0.weight`: shape=torch.Size([256, 256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.1.bev_encoder.ffn.layers.0.0.bias`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.1.bev_encoder.ffn.layers.1.weight`: shape=torch.Size([256, 256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.1.bev_encoder.ffn.layers.1.bias`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.1.aspp.input_conv.0.weight`: shape=torch.Size([64, 256, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.1.aspp.input_conv.1.weight`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.1.aspp.input_conv.1.bias`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.1.aspp.input_conv.1.running_mean`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.1.aspp.input_conv.1.running_var`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.1.aspp.input_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.1.aspp.aspp.aspp1.atrous_conv.weight`: shape=torch.Size([64, 64, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.1.aspp.aspp.aspp1.bn.weight`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.1.aspp.aspp.aspp1.bn.bias`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.1.aspp.aspp.aspp1.bn.running_mean`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.1.aspp.aspp.aspp1.bn.running_var`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.1.aspp.aspp.aspp1.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.1.aspp.aspp.aspp2.atrous_conv.weight`: shape=torch.Size([64, 64, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.1.aspp.aspp.aspp2.bn.weight`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.1.aspp.aspp.aspp2.bn.bias`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.1.aspp.aspp.aspp2.bn.running_mean`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.1.aspp.aspp.aspp2.bn.running_var`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.1.aspp.aspp.aspp2.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.1.aspp.aspp.aspp3.atrous_conv.weight`: shape=torch.Size([64, 64, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.1.aspp.aspp.aspp3.bn.weight`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.1.aspp.aspp.aspp3.bn.bias`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.1.aspp.aspp.aspp3.bn.running_mean`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.1.aspp.aspp.aspp3.bn.running_var`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.1.aspp.aspp.aspp3.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.1.aspp.aspp.aspp4.atrous_conv.weight`: shape=torch.Size([64, 64, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.1.aspp.aspp.aspp4.bn.weight`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.1.aspp.aspp.aspp4.bn.bias`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.1.aspp.aspp.aspp4.bn.running_mean`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.1.aspp.aspp.aspp4.bn.running_var`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.1.aspp.aspp.aspp4.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.1.aspp.aspp.global_avg_pool.1.weight`: shape=torch.Size([64, 64, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.1.aspp.aspp.global_avg_pool.2.weight`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.1.aspp.aspp.global_avg_pool.2.bias`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.1.aspp.aspp.global_avg_pool.2.running_mean`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.1.aspp.aspp.global_avg_pool.2.running_var`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.1.aspp.aspp.global_avg_pool.2.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.1.aspp.aspp.conv1.weight`: shape=torch.Size([64, 320, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.1.aspp.aspp.bn1.weight`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.1.aspp.aspp.bn1.bias`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.1.aspp.aspp.bn1.running_mean`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.1.aspp.aspp.bn1.running_var`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.1.aspp.aspp.bn1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.1.aspp.output_conv.0.weight`: shape=torch.Size([256, 64, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.1.aspp.output_conv.1.weight`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.1.aspp.output_conv.1.bias`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.1.aspp.output_conv.1.running_mean`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.1.aspp.output_conv.1.running_var`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.1.aspp.output_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.1.combine_coeff.weight`: shape=torch.Size([1, 256, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.2.1.combine_coeff.bias`: shape=torch.Size([1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.downsample.0.weight`: shape=torch.Size([512, 256, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.downsample.1.weight`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.downsample.1.bias`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.downsample.1.running_mean`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.downsample.1.running_var`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.downsample.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.input_conv.0.weight`: shape=torch.Size([512, 256, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.input_conv.1.weight`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.input_conv.1.bias`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.input_conv.1.running_mean`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.input_conv.1.running_var`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.input_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.bev_encoder.norm1.weight`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.bev_encoder.norm1.bias`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.bev_encoder.attn.w_msa.relative_position_bias_table`: shape=torch.Size([169, 16]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.bev_encoder.attn.w_msa.relative_position_index`: shape=torch.Size([49, 49]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.bev_encoder.attn.w_msa.qkv.weight`: shape=torch.Size([1536, 512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.bev_encoder.attn.w_msa.qkv.bias`: shape=torch.Size([1536]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.bev_encoder.attn.w_msa.proj.weight`: shape=torch.Size([512, 512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.bev_encoder.attn.w_msa.proj.bias`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.bev_encoder.norm2.weight`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.bev_encoder.norm2.bias`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.bev_encoder.ffn.layers.0.0.weight`: shape=torch.Size([512, 512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.bev_encoder.ffn.layers.0.0.bias`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.bev_encoder.ffn.layers.1.weight`: shape=torch.Size([512, 512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.bev_encoder.ffn.layers.1.bias`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.aspp.input_conv.0.weight`: shape=torch.Size([128, 512, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.aspp.input_conv.1.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.aspp.input_conv.1.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.aspp.input_conv.1.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.aspp.input_conv.1.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.aspp.input_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.aspp.aspp.aspp1.atrous_conv.weight`: shape=torch.Size([128, 128, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.aspp.aspp.aspp1.bn.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.aspp.aspp.aspp1.bn.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.aspp.aspp.aspp1.bn.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.aspp.aspp.aspp1.bn.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.aspp.aspp.aspp1.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.aspp.aspp.aspp2.atrous_conv.weight`: shape=torch.Size([128, 128, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.aspp.aspp.aspp2.bn.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.aspp.aspp.aspp2.bn.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.aspp.aspp.aspp2.bn.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.aspp.aspp.aspp2.bn.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.aspp.aspp.aspp2.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.aspp.aspp.aspp3.atrous_conv.weight`: shape=torch.Size([128, 128, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.aspp.aspp.aspp3.bn.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.aspp.aspp.aspp3.bn.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.aspp.aspp.aspp3.bn.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.aspp.aspp.aspp3.bn.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.aspp.aspp.aspp3.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.aspp.aspp.aspp4.atrous_conv.weight`: shape=torch.Size([128, 128, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.aspp.aspp.aspp4.bn.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.aspp.aspp.aspp4.bn.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.aspp.aspp.aspp4.bn.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.aspp.aspp.aspp4.bn.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.aspp.aspp.aspp4.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.aspp.aspp.global_avg_pool.1.weight`: shape=torch.Size([128, 128, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.aspp.aspp.global_avg_pool.2.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.aspp.aspp.global_avg_pool.2.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.aspp.aspp.global_avg_pool.2.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.aspp.aspp.global_avg_pool.2.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.aspp.aspp.global_avg_pool.2.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.aspp.aspp.conv1.weight`: shape=torch.Size([128, 640, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.aspp.aspp.bn1.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.aspp.aspp.bn1.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.aspp.aspp.bn1.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.aspp.aspp.bn1.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.aspp.aspp.bn1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.aspp.output_conv.0.weight`: shape=torch.Size([512, 128, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.aspp.output_conv.1.weight`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.aspp.output_conv.1.bias`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.aspp.output_conv.1.running_mean`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.aspp.output_conv.1.running_var`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.aspp.output_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.combine_coeff.weight`: shape=torch.Size([1, 512, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.0.combine_coeff.bias`: shape=torch.Size([1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.1.input_conv.0.weight`: shape=torch.Size([512, 512, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.1.input_conv.1.weight`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.1.input_conv.1.bias`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.1.input_conv.1.running_mean`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.1.input_conv.1.running_var`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.1.input_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.1.bev_encoder.norm1.weight`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.1.bev_encoder.norm1.bias`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.1.bev_encoder.attn.w_msa.relative_position_bias_table`: shape=torch.Size([169, 16]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.1.bev_encoder.attn.w_msa.relative_position_index`: shape=torch.Size([49, 49]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.1.bev_encoder.attn.w_msa.qkv.weight`: shape=torch.Size([1536, 512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.1.bev_encoder.attn.w_msa.qkv.bias`: shape=torch.Size([1536]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.1.bev_encoder.attn.w_msa.proj.weight`: shape=torch.Size([512, 512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.1.bev_encoder.attn.w_msa.proj.bias`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.1.bev_encoder.norm2.weight`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.1.bev_encoder.norm2.bias`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.1.bev_encoder.ffn.layers.0.0.weight`: shape=torch.Size([512, 512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.1.bev_encoder.ffn.layers.0.0.bias`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.1.bev_encoder.ffn.layers.1.weight`: shape=torch.Size([512, 512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.1.bev_encoder.ffn.layers.1.bias`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.1.aspp.input_conv.0.weight`: shape=torch.Size([128, 512, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.1.aspp.input_conv.1.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.1.aspp.input_conv.1.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.1.aspp.input_conv.1.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.1.aspp.input_conv.1.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.1.aspp.input_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.1.aspp.aspp.aspp1.atrous_conv.weight`: shape=torch.Size([128, 128, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.1.aspp.aspp.aspp1.bn.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.1.aspp.aspp.aspp1.bn.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.1.aspp.aspp.aspp1.bn.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.1.aspp.aspp.aspp1.bn.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.1.aspp.aspp.aspp1.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.1.aspp.aspp.aspp2.atrous_conv.weight`: shape=torch.Size([128, 128, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.1.aspp.aspp.aspp2.bn.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.1.aspp.aspp.aspp2.bn.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.1.aspp.aspp.aspp2.bn.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.1.aspp.aspp.aspp2.bn.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.1.aspp.aspp.aspp2.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.1.aspp.aspp.aspp3.atrous_conv.weight`: shape=torch.Size([128, 128, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.1.aspp.aspp.aspp3.bn.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.1.aspp.aspp.aspp3.bn.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.1.aspp.aspp.aspp3.bn.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.1.aspp.aspp.aspp3.bn.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.1.aspp.aspp.aspp3.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.1.aspp.aspp.aspp4.atrous_conv.weight`: shape=torch.Size([128, 128, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.1.aspp.aspp.aspp4.bn.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.1.aspp.aspp.aspp4.bn.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.1.aspp.aspp.aspp4.bn.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.1.aspp.aspp.aspp4.bn.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.1.aspp.aspp.aspp4.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.1.aspp.aspp.global_avg_pool.1.weight`: shape=torch.Size([128, 128, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.1.aspp.aspp.global_avg_pool.2.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.1.aspp.aspp.global_avg_pool.2.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.1.aspp.aspp.global_avg_pool.2.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.1.aspp.aspp.global_avg_pool.2.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.1.aspp.aspp.global_avg_pool.2.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.1.aspp.aspp.conv1.weight`: shape=torch.Size([128, 640, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.1.aspp.aspp.bn1.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.1.aspp.aspp.bn1.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.1.aspp.aspp.bn1.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.1.aspp.aspp.bn1.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.1.aspp.aspp.bn1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.1.aspp.output_conv.0.weight`: shape=torch.Size([512, 128, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.1.aspp.output_conv.1.weight`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.1.aspp.output_conv.1.bias`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.1.aspp.output_conv.1.running_mean`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.1.aspp.output_conv.1.running_var`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.1.aspp.output_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.1.combine_coeff.weight`: shape=torch.Size([1, 512, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xy.layers.3.1.combine_coeff.bias`: shape=torch.Size([1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.0.input_conv.0.weight`: shape=torch.Size([128, 128, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.0.input_conv.1.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.0.input_conv.1.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.0.input_conv.1.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.0.input_conv.1.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.0.input_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.0.bev_encoder.norm1.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.0.bev_encoder.norm1.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.0.bev_encoder.attn.w_msa.relative_position_bias_table`: shape=torch.Size([169, 4]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.0.bev_encoder.attn.w_msa.relative_position_index`: shape=torch.Size([49, 49]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.0.bev_encoder.attn.w_msa.qkv.weight`: shape=torch.Size([384, 128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.0.bev_encoder.attn.w_msa.qkv.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.0.bev_encoder.attn.w_msa.proj.weight`: shape=torch.Size([128, 128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.0.bev_encoder.attn.w_msa.proj.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.0.bev_encoder.norm2.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.0.bev_encoder.norm2.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.0.bev_encoder.ffn.layers.0.0.weight`: shape=torch.Size([128, 128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.0.bev_encoder.ffn.layers.0.0.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.0.bev_encoder.ffn.layers.1.weight`: shape=torch.Size([128, 128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.0.bev_encoder.ffn.layers.1.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.0.aspp.input_conv.0.weight`: shape=torch.Size([32, 128, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.0.aspp.input_conv.1.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.0.aspp.input_conv.1.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.0.aspp.input_conv.1.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.0.aspp.input_conv.1.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.0.aspp.input_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.0.aspp.aspp.aspp1.atrous_conv.weight`: shape=torch.Size([32, 32, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.0.aspp.aspp.aspp1.bn.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.0.aspp.aspp.aspp1.bn.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.0.aspp.aspp.aspp1.bn.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.0.aspp.aspp.aspp1.bn.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.0.aspp.aspp.aspp1.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.0.aspp.aspp.aspp2.atrous_conv.weight`: shape=torch.Size([32, 32, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.0.aspp.aspp.aspp2.bn.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.0.aspp.aspp.aspp2.bn.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.0.aspp.aspp.aspp2.bn.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.0.aspp.aspp.aspp2.bn.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.0.aspp.aspp.aspp2.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.0.aspp.aspp.aspp3.atrous_conv.weight`: shape=torch.Size([32, 32, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.0.aspp.aspp.aspp3.bn.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.0.aspp.aspp.aspp3.bn.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.0.aspp.aspp.aspp3.bn.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.0.aspp.aspp.aspp3.bn.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.0.aspp.aspp.aspp3.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.0.aspp.aspp.aspp4.atrous_conv.weight`: shape=torch.Size([32, 32, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.0.aspp.aspp.aspp4.bn.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.0.aspp.aspp.aspp4.bn.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.0.aspp.aspp.aspp4.bn.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.0.aspp.aspp.aspp4.bn.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.0.aspp.aspp.aspp4.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.0.aspp.aspp.global_avg_pool.1.weight`: shape=torch.Size([32, 32, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.0.aspp.aspp.global_avg_pool.2.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.0.aspp.aspp.global_avg_pool.2.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.0.aspp.aspp.global_avg_pool.2.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.0.aspp.aspp.global_avg_pool.2.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.0.aspp.aspp.global_avg_pool.2.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.0.aspp.aspp.conv1.weight`: shape=torch.Size([32, 160, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.0.aspp.aspp.bn1.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.0.aspp.aspp.bn1.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.0.aspp.aspp.bn1.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.0.aspp.aspp.bn1.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.0.aspp.aspp.bn1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.0.aspp.output_conv.0.weight`: shape=torch.Size([128, 32, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.0.aspp.output_conv.1.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.0.aspp.output_conv.1.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.0.aspp.output_conv.1.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.0.aspp.output_conv.1.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.0.aspp.output_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.0.combine_coeff.weight`: shape=torch.Size([1, 128, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.0.combine_coeff.bias`: shape=torch.Size([1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.1.input_conv.0.weight`: shape=torch.Size([128, 128, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.1.input_conv.1.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.1.input_conv.1.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.1.input_conv.1.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.1.input_conv.1.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.1.input_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.1.bev_encoder.norm1.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.1.bev_encoder.norm1.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.1.bev_encoder.attn.w_msa.relative_position_bias_table`: shape=torch.Size([169, 4]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.1.bev_encoder.attn.w_msa.relative_position_index`: shape=torch.Size([49, 49]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.1.bev_encoder.attn.w_msa.qkv.weight`: shape=torch.Size([384, 128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.1.bev_encoder.attn.w_msa.qkv.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.1.bev_encoder.attn.w_msa.proj.weight`: shape=torch.Size([128, 128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.1.bev_encoder.attn.w_msa.proj.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.1.bev_encoder.norm2.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.1.bev_encoder.norm2.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.1.bev_encoder.ffn.layers.0.0.weight`: shape=torch.Size([128, 128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.1.bev_encoder.ffn.layers.0.0.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.1.bev_encoder.ffn.layers.1.weight`: shape=torch.Size([128, 128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.1.bev_encoder.ffn.layers.1.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.1.aspp.input_conv.0.weight`: shape=torch.Size([32, 128, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.1.aspp.input_conv.1.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.1.aspp.input_conv.1.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.1.aspp.input_conv.1.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.1.aspp.input_conv.1.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.1.aspp.input_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.1.aspp.aspp.aspp1.atrous_conv.weight`: shape=torch.Size([32, 32, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.1.aspp.aspp.aspp1.bn.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.1.aspp.aspp.aspp1.bn.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.1.aspp.aspp.aspp1.bn.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.1.aspp.aspp.aspp1.bn.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.1.aspp.aspp.aspp1.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.1.aspp.aspp.aspp2.atrous_conv.weight`: shape=torch.Size([32, 32, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.1.aspp.aspp.aspp2.bn.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.1.aspp.aspp.aspp2.bn.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.1.aspp.aspp.aspp2.bn.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.1.aspp.aspp.aspp2.bn.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.1.aspp.aspp.aspp2.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.1.aspp.aspp.aspp3.atrous_conv.weight`: shape=torch.Size([32, 32, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.1.aspp.aspp.aspp3.bn.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.1.aspp.aspp.aspp3.bn.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.1.aspp.aspp.aspp3.bn.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.1.aspp.aspp.aspp3.bn.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.1.aspp.aspp.aspp3.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.1.aspp.aspp.aspp4.atrous_conv.weight`: shape=torch.Size([32, 32, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.1.aspp.aspp.aspp4.bn.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.1.aspp.aspp.aspp4.bn.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.1.aspp.aspp.aspp4.bn.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.1.aspp.aspp.aspp4.bn.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.1.aspp.aspp.aspp4.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.1.aspp.aspp.global_avg_pool.1.weight`: shape=torch.Size([32, 32, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.1.aspp.aspp.global_avg_pool.2.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.1.aspp.aspp.global_avg_pool.2.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.1.aspp.aspp.global_avg_pool.2.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.1.aspp.aspp.global_avg_pool.2.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.1.aspp.aspp.global_avg_pool.2.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.1.aspp.aspp.conv1.weight`: shape=torch.Size([32, 160, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.1.aspp.aspp.bn1.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.1.aspp.aspp.bn1.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.1.aspp.aspp.bn1.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.1.aspp.aspp.bn1.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.1.aspp.aspp.bn1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.1.aspp.output_conv.0.weight`: shape=torch.Size([128, 32, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.1.aspp.output_conv.1.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.1.aspp.output_conv.1.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.1.aspp.output_conv.1.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.1.aspp.output_conv.1.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.1.aspp.output_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.1.combine_coeff.weight`: shape=torch.Size([1, 128, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.0.1.combine_coeff.bias`: shape=torch.Size([1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.downsample.0.weight`: shape=torch.Size([128, 128, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.downsample.1.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.downsample.1.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.downsample.1.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.downsample.1.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.downsample.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.input_conv.0.weight`: shape=torch.Size([128, 128, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.input_conv.1.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.input_conv.1.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.input_conv.1.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.input_conv.1.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.input_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.bev_encoder.norm1.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.bev_encoder.norm1.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.bev_encoder.attn.w_msa.relative_position_bias_table`: shape=torch.Size([169, 4]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.bev_encoder.attn.w_msa.relative_position_index`: shape=torch.Size([49, 49]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.bev_encoder.attn.w_msa.qkv.weight`: shape=torch.Size([384, 128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.bev_encoder.attn.w_msa.qkv.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.bev_encoder.attn.w_msa.proj.weight`: shape=torch.Size([128, 128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.bev_encoder.attn.w_msa.proj.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.bev_encoder.norm2.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.bev_encoder.norm2.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.bev_encoder.ffn.layers.0.0.weight`: shape=torch.Size([128, 128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.bev_encoder.ffn.layers.0.0.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.bev_encoder.ffn.layers.1.weight`: shape=torch.Size([128, 128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.bev_encoder.ffn.layers.1.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.aspp.input_conv.0.weight`: shape=torch.Size([32, 128, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.aspp.input_conv.1.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.aspp.input_conv.1.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.aspp.input_conv.1.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.aspp.input_conv.1.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.aspp.input_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.aspp.aspp.aspp1.atrous_conv.weight`: shape=torch.Size([32, 32, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.aspp.aspp.aspp1.bn.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.aspp.aspp.aspp1.bn.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.aspp.aspp.aspp1.bn.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.aspp.aspp.aspp1.bn.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.aspp.aspp.aspp1.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.aspp.aspp.aspp2.atrous_conv.weight`: shape=torch.Size([32, 32, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.aspp.aspp.aspp2.bn.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.aspp.aspp.aspp2.bn.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.aspp.aspp.aspp2.bn.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.aspp.aspp.aspp2.bn.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.aspp.aspp.aspp2.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.aspp.aspp.aspp3.atrous_conv.weight`: shape=torch.Size([32, 32, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.aspp.aspp.aspp3.bn.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.aspp.aspp.aspp3.bn.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.aspp.aspp.aspp3.bn.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.aspp.aspp.aspp3.bn.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.aspp.aspp.aspp3.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.aspp.aspp.aspp4.atrous_conv.weight`: shape=torch.Size([32, 32, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.aspp.aspp.aspp4.bn.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.aspp.aspp.aspp4.bn.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.aspp.aspp.aspp4.bn.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.aspp.aspp.aspp4.bn.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.aspp.aspp.aspp4.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.aspp.aspp.global_avg_pool.1.weight`: shape=torch.Size([32, 32, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.aspp.aspp.global_avg_pool.2.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.aspp.aspp.global_avg_pool.2.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.aspp.aspp.global_avg_pool.2.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.aspp.aspp.global_avg_pool.2.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.aspp.aspp.global_avg_pool.2.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.aspp.aspp.conv1.weight`: shape=torch.Size([32, 160, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.aspp.aspp.bn1.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.aspp.aspp.bn1.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.aspp.aspp.bn1.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.aspp.aspp.bn1.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.aspp.aspp.bn1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.aspp.output_conv.0.weight`: shape=torch.Size([128, 32, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.aspp.output_conv.1.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.aspp.output_conv.1.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.aspp.output_conv.1.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.aspp.output_conv.1.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.aspp.output_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.combine_coeff.weight`: shape=torch.Size([1, 128, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.0.combine_coeff.bias`: shape=torch.Size([1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.1.input_conv.0.weight`: shape=torch.Size([128, 128, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.1.input_conv.1.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.1.input_conv.1.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.1.input_conv.1.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.1.input_conv.1.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.1.input_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.1.bev_encoder.norm1.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.1.bev_encoder.norm1.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.1.bev_encoder.attn.w_msa.relative_position_bias_table`: shape=torch.Size([169, 4]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.1.bev_encoder.attn.w_msa.relative_position_index`: shape=torch.Size([49, 49]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.1.bev_encoder.attn.w_msa.qkv.weight`: shape=torch.Size([384, 128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.1.bev_encoder.attn.w_msa.qkv.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.1.bev_encoder.attn.w_msa.proj.weight`: shape=torch.Size([128, 128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.1.bev_encoder.attn.w_msa.proj.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.1.bev_encoder.norm2.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.1.bev_encoder.norm2.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.1.bev_encoder.ffn.layers.0.0.weight`: shape=torch.Size([128, 128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.1.bev_encoder.ffn.layers.0.0.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.1.bev_encoder.ffn.layers.1.weight`: shape=torch.Size([128, 128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.1.bev_encoder.ffn.layers.1.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.1.aspp.input_conv.0.weight`: shape=torch.Size([32, 128, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.1.aspp.input_conv.1.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.1.aspp.input_conv.1.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.1.aspp.input_conv.1.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.1.aspp.input_conv.1.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.1.aspp.input_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.1.aspp.aspp.aspp1.atrous_conv.weight`: shape=torch.Size([32, 32, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.1.aspp.aspp.aspp1.bn.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.1.aspp.aspp.aspp1.bn.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.1.aspp.aspp.aspp1.bn.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.1.aspp.aspp.aspp1.bn.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.1.aspp.aspp.aspp1.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.1.aspp.aspp.aspp2.atrous_conv.weight`: shape=torch.Size([32, 32, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.1.aspp.aspp.aspp2.bn.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.1.aspp.aspp.aspp2.bn.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.1.aspp.aspp.aspp2.bn.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.1.aspp.aspp.aspp2.bn.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.1.aspp.aspp.aspp2.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.1.aspp.aspp.aspp3.atrous_conv.weight`: shape=torch.Size([32, 32, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.1.aspp.aspp.aspp3.bn.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.1.aspp.aspp.aspp3.bn.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.1.aspp.aspp.aspp3.bn.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.1.aspp.aspp.aspp3.bn.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.1.aspp.aspp.aspp3.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.1.aspp.aspp.aspp4.atrous_conv.weight`: shape=torch.Size([32, 32, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.1.aspp.aspp.aspp4.bn.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.1.aspp.aspp.aspp4.bn.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.1.aspp.aspp.aspp4.bn.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.1.aspp.aspp.aspp4.bn.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.1.aspp.aspp.aspp4.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.1.aspp.aspp.global_avg_pool.1.weight`: shape=torch.Size([32, 32, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.1.aspp.aspp.global_avg_pool.2.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.1.aspp.aspp.global_avg_pool.2.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.1.aspp.aspp.global_avg_pool.2.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.1.aspp.aspp.global_avg_pool.2.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.1.aspp.aspp.global_avg_pool.2.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.1.aspp.aspp.conv1.weight`: shape=torch.Size([32, 160, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.1.aspp.aspp.bn1.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.1.aspp.aspp.bn1.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.1.aspp.aspp.bn1.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.1.aspp.aspp.bn1.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.1.aspp.aspp.bn1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.1.aspp.output_conv.0.weight`: shape=torch.Size([128, 32, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.1.aspp.output_conv.1.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.1.aspp.output_conv.1.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.1.aspp.output_conv.1.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.1.aspp.output_conv.1.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.1.aspp.output_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.1.combine_coeff.weight`: shape=torch.Size([1, 128, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.1.1.combine_coeff.bias`: shape=torch.Size([1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.downsample.0.weight`: shape=torch.Size([256, 128, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.downsample.1.weight`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.downsample.1.bias`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.downsample.1.running_mean`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.downsample.1.running_var`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.downsample.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.input_conv.0.weight`: shape=torch.Size([256, 128, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.input_conv.1.weight`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.input_conv.1.bias`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.input_conv.1.running_mean`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.input_conv.1.running_var`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.input_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.bev_encoder.norm1.weight`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.bev_encoder.norm1.bias`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.bev_encoder.attn.w_msa.relative_position_bias_table`: shape=torch.Size([169, 8]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.bev_encoder.attn.w_msa.relative_position_index`: shape=torch.Size([49, 49]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.bev_encoder.attn.w_msa.qkv.weight`: shape=torch.Size([768, 256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.bev_encoder.attn.w_msa.qkv.bias`: shape=torch.Size([768]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.bev_encoder.attn.w_msa.proj.weight`: shape=torch.Size([256, 256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.bev_encoder.attn.w_msa.proj.bias`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.bev_encoder.norm2.weight`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.bev_encoder.norm2.bias`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.bev_encoder.ffn.layers.0.0.weight`: shape=torch.Size([256, 256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.bev_encoder.ffn.layers.0.0.bias`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.bev_encoder.ffn.layers.1.weight`: shape=torch.Size([256, 256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.bev_encoder.ffn.layers.1.bias`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.aspp.input_conv.0.weight`: shape=torch.Size([64, 256, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.aspp.input_conv.1.weight`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.aspp.input_conv.1.bias`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.aspp.input_conv.1.running_mean`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.aspp.input_conv.1.running_var`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.aspp.input_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.aspp.aspp.aspp1.atrous_conv.weight`: shape=torch.Size([64, 64, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.aspp.aspp.aspp1.bn.weight`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.aspp.aspp.aspp1.bn.bias`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.aspp.aspp.aspp1.bn.running_mean`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.aspp.aspp.aspp1.bn.running_var`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.aspp.aspp.aspp1.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.aspp.aspp.aspp2.atrous_conv.weight`: shape=torch.Size([64, 64, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.aspp.aspp.aspp2.bn.weight`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.aspp.aspp.aspp2.bn.bias`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.aspp.aspp.aspp2.bn.running_mean`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.aspp.aspp.aspp2.bn.running_var`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.aspp.aspp.aspp2.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.aspp.aspp.aspp3.atrous_conv.weight`: shape=torch.Size([64, 64, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.aspp.aspp.aspp3.bn.weight`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.aspp.aspp.aspp3.bn.bias`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.aspp.aspp.aspp3.bn.running_mean`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.aspp.aspp.aspp3.bn.running_var`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.aspp.aspp.aspp3.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.aspp.aspp.aspp4.atrous_conv.weight`: shape=torch.Size([64, 64, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.aspp.aspp.aspp4.bn.weight`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.aspp.aspp.aspp4.bn.bias`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.aspp.aspp.aspp4.bn.running_mean`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.aspp.aspp.aspp4.bn.running_var`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.aspp.aspp.aspp4.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.aspp.aspp.global_avg_pool.1.weight`: shape=torch.Size([64, 64, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.aspp.aspp.global_avg_pool.2.weight`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.aspp.aspp.global_avg_pool.2.bias`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.aspp.aspp.global_avg_pool.2.running_mean`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.aspp.aspp.global_avg_pool.2.running_var`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.aspp.aspp.global_avg_pool.2.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.aspp.aspp.conv1.weight`: shape=torch.Size([64, 320, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.aspp.aspp.bn1.weight`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.aspp.aspp.bn1.bias`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.aspp.aspp.bn1.running_mean`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.aspp.aspp.bn1.running_var`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.aspp.aspp.bn1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.aspp.output_conv.0.weight`: shape=torch.Size([256, 64, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.aspp.output_conv.1.weight`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.aspp.output_conv.1.bias`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.aspp.output_conv.1.running_mean`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.aspp.output_conv.1.running_var`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.aspp.output_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.combine_coeff.weight`: shape=torch.Size([1, 256, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.0.combine_coeff.bias`: shape=torch.Size([1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.1.input_conv.0.weight`: shape=torch.Size([256, 256, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.1.input_conv.1.weight`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.1.input_conv.1.bias`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.1.input_conv.1.running_mean`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.1.input_conv.1.running_var`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.1.input_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.1.bev_encoder.norm1.weight`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.1.bev_encoder.norm1.bias`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.1.bev_encoder.attn.w_msa.relative_position_bias_table`: shape=torch.Size([169, 8]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.1.bev_encoder.attn.w_msa.relative_position_index`: shape=torch.Size([49, 49]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.1.bev_encoder.attn.w_msa.qkv.weight`: shape=torch.Size([768, 256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.1.bev_encoder.attn.w_msa.qkv.bias`: shape=torch.Size([768]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.1.bev_encoder.attn.w_msa.proj.weight`: shape=torch.Size([256, 256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.1.bev_encoder.attn.w_msa.proj.bias`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.1.bev_encoder.norm2.weight`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.1.bev_encoder.norm2.bias`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.1.bev_encoder.ffn.layers.0.0.weight`: shape=torch.Size([256, 256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.1.bev_encoder.ffn.layers.0.0.bias`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.1.bev_encoder.ffn.layers.1.weight`: shape=torch.Size([256, 256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.1.bev_encoder.ffn.layers.1.bias`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.1.aspp.input_conv.0.weight`: shape=torch.Size([64, 256, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.1.aspp.input_conv.1.weight`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.1.aspp.input_conv.1.bias`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.1.aspp.input_conv.1.running_mean`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.1.aspp.input_conv.1.running_var`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.1.aspp.input_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.1.aspp.aspp.aspp1.atrous_conv.weight`: shape=torch.Size([64, 64, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.1.aspp.aspp.aspp1.bn.weight`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.1.aspp.aspp.aspp1.bn.bias`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.1.aspp.aspp.aspp1.bn.running_mean`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.1.aspp.aspp.aspp1.bn.running_var`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.1.aspp.aspp.aspp1.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.1.aspp.aspp.aspp2.atrous_conv.weight`: shape=torch.Size([64, 64, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.1.aspp.aspp.aspp2.bn.weight`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.1.aspp.aspp.aspp2.bn.bias`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.1.aspp.aspp.aspp2.bn.running_mean`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.1.aspp.aspp.aspp2.bn.running_var`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.1.aspp.aspp.aspp2.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.1.aspp.aspp.aspp3.atrous_conv.weight`: shape=torch.Size([64, 64, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.1.aspp.aspp.aspp3.bn.weight`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.1.aspp.aspp.aspp3.bn.bias`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.1.aspp.aspp.aspp3.bn.running_mean`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.1.aspp.aspp.aspp3.bn.running_var`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.1.aspp.aspp.aspp3.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.1.aspp.aspp.aspp4.atrous_conv.weight`: shape=torch.Size([64, 64, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.1.aspp.aspp.aspp4.bn.weight`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.1.aspp.aspp.aspp4.bn.bias`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.1.aspp.aspp.aspp4.bn.running_mean`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.1.aspp.aspp.aspp4.bn.running_var`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.1.aspp.aspp.aspp4.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.1.aspp.aspp.global_avg_pool.1.weight`: shape=torch.Size([64, 64, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.1.aspp.aspp.global_avg_pool.2.weight`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.1.aspp.aspp.global_avg_pool.2.bias`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.1.aspp.aspp.global_avg_pool.2.running_mean`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.1.aspp.aspp.global_avg_pool.2.running_var`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.1.aspp.aspp.global_avg_pool.2.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.1.aspp.aspp.conv1.weight`: shape=torch.Size([64, 320, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.1.aspp.aspp.bn1.weight`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.1.aspp.aspp.bn1.bias`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.1.aspp.aspp.bn1.running_mean`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.1.aspp.aspp.bn1.running_var`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.1.aspp.aspp.bn1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.1.aspp.output_conv.0.weight`: shape=torch.Size([256, 64, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.1.aspp.output_conv.1.weight`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.1.aspp.output_conv.1.bias`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.1.aspp.output_conv.1.running_mean`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.1.aspp.output_conv.1.running_var`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.1.aspp.output_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.1.combine_coeff.weight`: shape=torch.Size([1, 256, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.2.1.combine_coeff.bias`: shape=torch.Size([1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.downsample.0.weight`: shape=torch.Size([512, 256, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.downsample.1.weight`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.downsample.1.bias`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.downsample.1.running_mean`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.downsample.1.running_var`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.downsample.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.input_conv.0.weight`: shape=torch.Size([512, 256, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.input_conv.1.weight`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.input_conv.1.bias`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.input_conv.1.running_mean`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.input_conv.1.running_var`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.input_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.bev_encoder.norm1.weight`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.bev_encoder.norm1.bias`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.bev_encoder.attn.w_msa.relative_position_bias_table`: shape=torch.Size([169, 16]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.bev_encoder.attn.w_msa.relative_position_index`: shape=torch.Size([49, 49]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.bev_encoder.attn.w_msa.qkv.weight`: shape=torch.Size([1536, 512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.bev_encoder.attn.w_msa.qkv.bias`: shape=torch.Size([1536]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.bev_encoder.attn.w_msa.proj.weight`: shape=torch.Size([512, 512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.bev_encoder.attn.w_msa.proj.bias`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.bev_encoder.norm2.weight`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.bev_encoder.norm2.bias`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.bev_encoder.ffn.layers.0.0.weight`: shape=torch.Size([512, 512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.bev_encoder.ffn.layers.0.0.bias`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.bev_encoder.ffn.layers.1.weight`: shape=torch.Size([512, 512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.bev_encoder.ffn.layers.1.bias`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.aspp.input_conv.0.weight`: shape=torch.Size([128, 512, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.aspp.input_conv.1.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.aspp.input_conv.1.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.aspp.input_conv.1.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.aspp.input_conv.1.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.aspp.input_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.aspp.aspp.aspp1.atrous_conv.weight`: shape=torch.Size([128, 128, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.aspp.aspp.aspp1.bn.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.aspp.aspp.aspp1.bn.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.aspp.aspp.aspp1.bn.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.aspp.aspp.aspp1.bn.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.aspp.aspp.aspp1.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.aspp.aspp.aspp2.atrous_conv.weight`: shape=torch.Size([128, 128, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.aspp.aspp.aspp2.bn.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.aspp.aspp.aspp2.bn.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.aspp.aspp.aspp2.bn.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.aspp.aspp.aspp2.bn.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.aspp.aspp.aspp2.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.aspp.aspp.aspp3.atrous_conv.weight`: shape=torch.Size([128, 128, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.aspp.aspp.aspp3.bn.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.aspp.aspp.aspp3.bn.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.aspp.aspp.aspp3.bn.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.aspp.aspp.aspp3.bn.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.aspp.aspp.aspp3.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.aspp.aspp.aspp4.atrous_conv.weight`: shape=torch.Size([128, 128, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.aspp.aspp.aspp4.bn.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.aspp.aspp.aspp4.bn.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.aspp.aspp.aspp4.bn.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.aspp.aspp.aspp4.bn.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.aspp.aspp.aspp4.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.aspp.aspp.global_avg_pool.1.weight`: shape=torch.Size([128, 128, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.aspp.aspp.global_avg_pool.2.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.aspp.aspp.global_avg_pool.2.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.aspp.aspp.global_avg_pool.2.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.aspp.aspp.global_avg_pool.2.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.aspp.aspp.global_avg_pool.2.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.aspp.aspp.conv1.weight`: shape=torch.Size([128, 640, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.aspp.aspp.bn1.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.aspp.aspp.bn1.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.aspp.aspp.bn1.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.aspp.aspp.bn1.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.aspp.aspp.bn1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.aspp.output_conv.0.weight`: shape=torch.Size([512, 128, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.aspp.output_conv.1.weight`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.aspp.output_conv.1.bias`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.aspp.output_conv.1.running_mean`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.aspp.output_conv.1.running_var`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.aspp.output_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.combine_coeff.weight`: shape=torch.Size([1, 512, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.0.combine_coeff.bias`: shape=torch.Size([1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.1.input_conv.0.weight`: shape=torch.Size([512, 512, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.1.input_conv.1.weight`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.1.input_conv.1.bias`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.1.input_conv.1.running_mean`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.1.input_conv.1.running_var`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.1.input_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.1.bev_encoder.norm1.weight`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.1.bev_encoder.norm1.bias`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.1.bev_encoder.attn.w_msa.relative_position_bias_table`: shape=torch.Size([169, 16]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.1.bev_encoder.attn.w_msa.relative_position_index`: shape=torch.Size([49, 49]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.1.bev_encoder.attn.w_msa.qkv.weight`: shape=torch.Size([1536, 512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.1.bev_encoder.attn.w_msa.qkv.bias`: shape=torch.Size([1536]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.1.bev_encoder.attn.w_msa.proj.weight`: shape=torch.Size([512, 512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.1.bev_encoder.attn.w_msa.proj.bias`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.1.bev_encoder.norm2.weight`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.1.bev_encoder.norm2.bias`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.1.bev_encoder.ffn.layers.0.0.weight`: shape=torch.Size([512, 512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.1.bev_encoder.ffn.layers.0.0.bias`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.1.bev_encoder.ffn.layers.1.weight`: shape=torch.Size([512, 512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.1.bev_encoder.ffn.layers.1.bias`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.1.aspp.input_conv.0.weight`: shape=torch.Size([128, 512, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.1.aspp.input_conv.1.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.1.aspp.input_conv.1.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.1.aspp.input_conv.1.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.1.aspp.input_conv.1.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.1.aspp.input_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.1.aspp.aspp.aspp1.atrous_conv.weight`: shape=torch.Size([128, 128, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.1.aspp.aspp.aspp1.bn.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.1.aspp.aspp.aspp1.bn.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.1.aspp.aspp.aspp1.bn.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.1.aspp.aspp.aspp1.bn.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.1.aspp.aspp.aspp1.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.1.aspp.aspp.aspp2.atrous_conv.weight`: shape=torch.Size([128, 128, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.1.aspp.aspp.aspp2.bn.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.1.aspp.aspp.aspp2.bn.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.1.aspp.aspp.aspp2.bn.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.1.aspp.aspp.aspp2.bn.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.1.aspp.aspp.aspp2.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.1.aspp.aspp.aspp3.atrous_conv.weight`: shape=torch.Size([128, 128, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.1.aspp.aspp.aspp3.bn.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.1.aspp.aspp.aspp3.bn.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.1.aspp.aspp.aspp3.bn.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.1.aspp.aspp.aspp3.bn.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.1.aspp.aspp.aspp3.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.1.aspp.aspp.aspp4.atrous_conv.weight`: shape=torch.Size([128, 128, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.1.aspp.aspp.aspp4.bn.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.1.aspp.aspp.aspp4.bn.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.1.aspp.aspp.aspp4.bn.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.1.aspp.aspp.aspp4.bn.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.1.aspp.aspp.aspp4.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.1.aspp.aspp.global_avg_pool.1.weight`: shape=torch.Size([128, 128, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.1.aspp.aspp.global_avg_pool.2.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.1.aspp.aspp.global_avg_pool.2.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.1.aspp.aspp.global_avg_pool.2.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.1.aspp.aspp.global_avg_pool.2.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.1.aspp.aspp.global_avg_pool.2.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.1.aspp.aspp.conv1.weight`: shape=torch.Size([128, 640, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.1.aspp.aspp.bn1.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.1.aspp.aspp.bn1.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.1.aspp.aspp.bn1.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.1.aspp.aspp.bn1.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.1.aspp.aspp.bn1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.1.aspp.output_conv.0.weight`: shape=torch.Size([512, 128, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.1.aspp.output_conv.1.weight`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.1.aspp.output_conv.1.bias`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.1.aspp.output_conv.1.running_mean`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.1.aspp.output_conv.1.running_var`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.1.aspp.output_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.1.combine_coeff.weight`: shape=torch.Size([1, 512, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_yz.layers.3.1.combine_coeff.bias`: shape=torch.Size([1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.0.input_conv.0.weight`: shape=torch.Size([128, 128, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.0.input_conv.1.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.0.input_conv.1.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.0.input_conv.1.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.0.input_conv.1.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.0.input_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.0.bev_encoder.norm1.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.0.bev_encoder.norm1.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.0.bev_encoder.attn.w_msa.relative_position_bias_table`: shape=torch.Size([169, 4]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.0.bev_encoder.attn.w_msa.relative_position_index`: shape=torch.Size([49, 49]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.0.bev_encoder.attn.w_msa.qkv.weight`: shape=torch.Size([384, 128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.0.bev_encoder.attn.w_msa.qkv.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.0.bev_encoder.attn.w_msa.proj.weight`: shape=torch.Size([128, 128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.0.bev_encoder.attn.w_msa.proj.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.0.bev_encoder.norm2.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.0.bev_encoder.norm2.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.0.bev_encoder.ffn.layers.0.0.weight`: shape=torch.Size([128, 128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.0.bev_encoder.ffn.layers.0.0.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.0.bev_encoder.ffn.layers.1.weight`: shape=torch.Size([128, 128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.0.bev_encoder.ffn.layers.1.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.0.aspp.input_conv.0.weight`: shape=torch.Size([32, 128, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.0.aspp.input_conv.1.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.0.aspp.input_conv.1.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.0.aspp.input_conv.1.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.0.aspp.input_conv.1.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.0.aspp.input_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.0.aspp.aspp.aspp1.atrous_conv.weight`: shape=torch.Size([32, 32, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.0.aspp.aspp.aspp1.bn.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.0.aspp.aspp.aspp1.bn.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.0.aspp.aspp.aspp1.bn.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.0.aspp.aspp.aspp1.bn.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.0.aspp.aspp.aspp1.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.0.aspp.aspp.aspp2.atrous_conv.weight`: shape=torch.Size([32, 32, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.0.aspp.aspp.aspp2.bn.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.0.aspp.aspp.aspp2.bn.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.0.aspp.aspp.aspp2.bn.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.0.aspp.aspp.aspp2.bn.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.0.aspp.aspp.aspp2.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.0.aspp.aspp.aspp3.atrous_conv.weight`: shape=torch.Size([32, 32, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.0.aspp.aspp.aspp3.bn.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.0.aspp.aspp.aspp3.bn.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.0.aspp.aspp.aspp3.bn.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.0.aspp.aspp.aspp3.bn.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.0.aspp.aspp.aspp3.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.0.aspp.aspp.aspp4.atrous_conv.weight`: shape=torch.Size([32, 32, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.0.aspp.aspp.aspp4.bn.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.0.aspp.aspp.aspp4.bn.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.0.aspp.aspp.aspp4.bn.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.0.aspp.aspp.aspp4.bn.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.0.aspp.aspp.aspp4.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.0.aspp.aspp.global_avg_pool.1.weight`: shape=torch.Size([32, 32, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.0.aspp.aspp.global_avg_pool.2.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.0.aspp.aspp.global_avg_pool.2.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.0.aspp.aspp.global_avg_pool.2.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.0.aspp.aspp.global_avg_pool.2.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.0.aspp.aspp.global_avg_pool.2.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.0.aspp.aspp.conv1.weight`: shape=torch.Size([32, 160, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.0.aspp.aspp.bn1.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.0.aspp.aspp.bn1.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.0.aspp.aspp.bn1.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.0.aspp.aspp.bn1.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.0.aspp.aspp.bn1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.0.aspp.output_conv.0.weight`: shape=torch.Size([128, 32, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.0.aspp.output_conv.1.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.0.aspp.output_conv.1.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.0.aspp.output_conv.1.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.0.aspp.output_conv.1.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.0.aspp.output_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.0.combine_coeff.weight`: shape=torch.Size([1, 128, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.0.combine_coeff.bias`: shape=torch.Size([1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.1.input_conv.0.weight`: shape=torch.Size([128, 128, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.1.input_conv.1.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.1.input_conv.1.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.1.input_conv.1.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.1.input_conv.1.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.1.input_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.1.bev_encoder.norm1.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.1.bev_encoder.norm1.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.1.bev_encoder.attn.w_msa.relative_position_bias_table`: shape=torch.Size([169, 4]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.1.bev_encoder.attn.w_msa.relative_position_index`: shape=torch.Size([49, 49]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.1.bev_encoder.attn.w_msa.qkv.weight`: shape=torch.Size([384, 128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.1.bev_encoder.attn.w_msa.qkv.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.1.bev_encoder.attn.w_msa.proj.weight`: shape=torch.Size([128, 128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.1.bev_encoder.attn.w_msa.proj.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.1.bev_encoder.norm2.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.1.bev_encoder.norm2.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.1.bev_encoder.ffn.layers.0.0.weight`: shape=torch.Size([128, 128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.1.bev_encoder.ffn.layers.0.0.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.1.bev_encoder.ffn.layers.1.weight`: shape=torch.Size([128, 128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.1.bev_encoder.ffn.layers.1.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.1.aspp.input_conv.0.weight`: shape=torch.Size([32, 128, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.1.aspp.input_conv.1.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.1.aspp.input_conv.1.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.1.aspp.input_conv.1.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.1.aspp.input_conv.1.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.1.aspp.input_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.1.aspp.aspp.aspp1.atrous_conv.weight`: shape=torch.Size([32, 32, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.1.aspp.aspp.aspp1.bn.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.1.aspp.aspp.aspp1.bn.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.1.aspp.aspp.aspp1.bn.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.1.aspp.aspp.aspp1.bn.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.1.aspp.aspp.aspp1.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.1.aspp.aspp.aspp2.atrous_conv.weight`: shape=torch.Size([32, 32, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.1.aspp.aspp.aspp2.bn.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.1.aspp.aspp.aspp2.bn.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.1.aspp.aspp.aspp2.bn.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.1.aspp.aspp.aspp2.bn.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.1.aspp.aspp.aspp2.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.1.aspp.aspp.aspp3.atrous_conv.weight`: shape=torch.Size([32, 32, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.1.aspp.aspp.aspp3.bn.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.1.aspp.aspp.aspp3.bn.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.1.aspp.aspp.aspp3.bn.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.1.aspp.aspp.aspp3.bn.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.1.aspp.aspp.aspp3.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.1.aspp.aspp.aspp4.atrous_conv.weight`: shape=torch.Size([32, 32, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.1.aspp.aspp.aspp4.bn.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.1.aspp.aspp.aspp4.bn.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.1.aspp.aspp.aspp4.bn.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.1.aspp.aspp.aspp4.bn.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.1.aspp.aspp.aspp4.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.1.aspp.aspp.global_avg_pool.1.weight`: shape=torch.Size([32, 32, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.1.aspp.aspp.global_avg_pool.2.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.1.aspp.aspp.global_avg_pool.2.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.1.aspp.aspp.global_avg_pool.2.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.1.aspp.aspp.global_avg_pool.2.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.1.aspp.aspp.global_avg_pool.2.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.1.aspp.aspp.conv1.weight`: shape=torch.Size([32, 160, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.1.aspp.aspp.bn1.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.1.aspp.aspp.bn1.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.1.aspp.aspp.bn1.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.1.aspp.aspp.bn1.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.1.aspp.aspp.bn1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.1.aspp.output_conv.0.weight`: shape=torch.Size([128, 32, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.1.aspp.output_conv.1.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.1.aspp.output_conv.1.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.1.aspp.output_conv.1.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.1.aspp.output_conv.1.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.1.aspp.output_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.1.combine_coeff.weight`: shape=torch.Size([1, 128, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.0.1.combine_coeff.bias`: shape=torch.Size([1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.downsample.0.weight`: shape=torch.Size([128, 128, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.downsample.1.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.downsample.1.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.downsample.1.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.downsample.1.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.downsample.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.input_conv.0.weight`: shape=torch.Size([128, 128, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.input_conv.1.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.input_conv.1.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.input_conv.1.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.input_conv.1.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.input_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.bev_encoder.norm1.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.bev_encoder.norm1.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.bev_encoder.attn.w_msa.relative_position_bias_table`: shape=torch.Size([169, 4]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.bev_encoder.attn.w_msa.relative_position_index`: shape=torch.Size([49, 49]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.bev_encoder.attn.w_msa.qkv.weight`: shape=torch.Size([384, 128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.bev_encoder.attn.w_msa.qkv.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.bev_encoder.attn.w_msa.proj.weight`: shape=torch.Size([128, 128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.bev_encoder.attn.w_msa.proj.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.bev_encoder.norm2.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.bev_encoder.norm2.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.bev_encoder.ffn.layers.0.0.weight`: shape=torch.Size([128, 128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.bev_encoder.ffn.layers.0.0.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.bev_encoder.ffn.layers.1.weight`: shape=torch.Size([128, 128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.bev_encoder.ffn.layers.1.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.aspp.input_conv.0.weight`: shape=torch.Size([32, 128, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.aspp.input_conv.1.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.aspp.input_conv.1.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.aspp.input_conv.1.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.aspp.input_conv.1.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.aspp.input_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.aspp.aspp.aspp1.atrous_conv.weight`: shape=torch.Size([32, 32, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.aspp.aspp.aspp1.bn.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.aspp.aspp.aspp1.bn.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.aspp.aspp.aspp1.bn.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.aspp.aspp.aspp1.bn.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.aspp.aspp.aspp1.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.aspp.aspp.aspp2.atrous_conv.weight`: shape=torch.Size([32, 32, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.aspp.aspp.aspp2.bn.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.aspp.aspp.aspp2.bn.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.aspp.aspp.aspp2.bn.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.aspp.aspp.aspp2.bn.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.aspp.aspp.aspp2.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.aspp.aspp.aspp3.atrous_conv.weight`: shape=torch.Size([32, 32, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.aspp.aspp.aspp3.bn.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.aspp.aspp.aspp3.bn.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.aspp.aspp.aspp3.bn.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.aspp.aspp.aspp3.bn.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.aspp.aspp.aspp3.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.aspp.aspp.aspp4.atrous_conv.weight`: shape=torch.Size([32, 32, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.aspp.aspp.aspp4.bn.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.aspp.aspp.aspp4.bn.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.aspp.aspp.aspp4.bn.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.aspp.aspp.aspp4.bn.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.aspp.aspp.aspp4.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.aspp.aspp.global_avg_pool.1.weight`: shape=torch.Size([32, 32, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.aspp.aspp.global_avg_pool.2.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.aspp.aspp.global_avg_pool.2.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.aspp.aspp.global_avg_pool.2.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.aspp.aspp.global_avg_pool.2.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.aspp.aspp.global_avg_pool.2.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.aspp.aspp.conv1.weight`: shape=torch.Size([32, 160, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.aspp.aspp.bn1.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.aspp.aspp.bn1.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.aspp.aspp.bn1.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.aspp.aspp.bn1.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.aspp.aspp.bn1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.aspp.output_conv.0.weight`: shape=torch.Size([128, 32, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.aspp.output_conv.1.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.aspp.output_conv.1.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.aspp.output_conv.1.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.aspp.output_conv.1.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.aspp.output_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.combine_coeff.weight`: shape=torch.Size([1, 128, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.0.combine_coeff.bias`: shape=torch.Size([1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.1.input_conv.0.weight`: shape=torch.Size([128, 128, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.1.input_conv.1.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.1.input_conv.1.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.1.input_conv.1.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.1.input_conv.1.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.1.input_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.1.bev_encoder.norm1.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.1.bev_encoder.norm1.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.1.bev_encoder.attn.w_msa.relative_position_bias_table`: shape=torch.Size([169, 4]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.1.bev_encoder.attn.w_msa.relative_position_index`: shape=torch.Size([49, 49]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.1.bev_encoder.attn.w_msa.qkv.weight`: shape=torch.Size([384, 128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.1.bev_encoder.attn.w_msa.qkv.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.1.bev_encoder.attn.w_msa.proj.weight`: shape=torch.Size([128, 128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.1.bev_encoder.attn.w_msa.proj.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.1.bev_encoder.norm2.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.1.bev_encoder.norm2.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.1.bev_encoder.ffn.layers.0.0.weight`: shape=torch.Size([128, 128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.1.bev_encoder.ffn.layers.0.0.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.1.bev_encoder.ffn.layers.1.weight`: shape=torch.Size([128, 128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.1.bev_encoder.ffn.layers.1.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.1.aspp.input_conv.0.weight`: shape=torch.Size([32, 128, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.1.aspp.input_conv.1.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.1.aspp.input_conv.1.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.1.aspp.input_conv.1.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.1.aspp.input_conv.1.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.1.aspp.input_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.1.aspp.aspp.aspp1.atrous_conv.weight`: shape=torch.Size([32, 32, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.1.aspp.aspp.aspp1.bn.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.1.aspp.aspp.aspp1.bn.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.1.aspp.aspp.aspp1.bn.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.1.aspp.aspp.aspp1.bn.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.1.aspp.aspp.aspp1.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.1.aspp.aspp.aspp2.atrous_conv.weight`: shape=torch.Size([32, 32, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.1.aspp.aspp.aspp2.bn.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.1.aspp.aspp.aspp2.bn.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.1.aspp.aspp.aspp2.bn.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.1.aspp.aspp.aspp2.bn.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.1.aspp.aspp.aspp2.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.1.aspp.aspp.aspp3.atrous_conv.weight`: shape=torch.Size([32, 32, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.1.aspp.aspp.aspp3.bn.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.1.aspp.aspp.aspp3.bn.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.1.aspp.aspp.aspp3.bn.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.1.aspp.aspp.aspp3.bn.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.1.aspp.aspp.aspp3.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.1.aspp.aspp.aspp4.atrous_conv.weight`: shape=torch.Size([32, 32, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.1.aspp.aspp.aspp4.bn.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.1.aspp.aspp.aspp4.bn.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.1.aspp.aspp.aspp4.bn.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.1.aspp.aspp.aspp4.bn.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.1.aspp.aspp.aspp4.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.1.aspp.aspp.global_avg_pool.1.weight`: shape=torch.Size([32, 32, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.1.aspp.aspp.global_avg_pool.2.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.1.aspp.aspp.global_avg_pool.2.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.1.aspp.aspp.global_avg_pool.2.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.1.aspp.aspp.global_avg_pool.2.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.1.aspp.aspp.global_avg_pool.2.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.1.aspp.aspp.conv1.weight`: shape=torch.Size([32, 160, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.1.aspp.aspp.bn1.weight`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.1.aspp.aspp.bn1.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.1.aspp.aspp.bn1.running_mean`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.1.aspp.aspp.bn1.running_var`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.1.aspp.aspp.bn1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.1.aspp.output_conv.0.weight`: shape=torch.Size([128, 32, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.1.aspp.output_conv.1.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.1.aspp.output_conv.1.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.1.aspp.output_conv.1.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.1.aspp.output_conv.1.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.1.aspp.output_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.1.combine_coeff.weight`: shape=torch.Size([1, 128, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.1.1.combine_coeff.bias`: shape=torch.Size([1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.downsample.0.weight`: shape=torch.Size([256, 128, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.downsample.1.weight`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.downsample.1.bias`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.downsample.1.running_mean`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.downsample.1.running_var`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.downsample.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.input_conv.0.weight`: shape=torch.Size([256, 128, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.input_conv.1.weight`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.input_conv.1.bias`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.input_conv.1.running_mean`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.input_conv.1.running_var`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.input_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.bev_encoder.norm1.weight`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.bev_encoder.norm1.bias`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.bev_encoder.attn.w_msa.relative_position_bias_table`: shape=torch.Size([169, 8]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.bev_encoder.attn.w_msa.relative_position_index`: shape=torch.Size([49, 49]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.bev_encoder.attn.w_msa.qkv.weight`: shape=torch.Size([768, 256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.bev_encoder.attn.w_msa.qkv.bias`: shape=torch.Size([768]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.bev_encoder.attn.w_msa.proj.weight`: shape=torch.Size([256, 256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.bev_encoder.attn.w_msa.proj.bias`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.bev_encoder.norm2.weight`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.bev_encoder.norm2.bias`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.bev_encoder.ffn.layers.0.0.weight`: shape=torch.Size([256, 256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.bev_encoder.ffn.layers.0.0.bias`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.bev_encoder.ffn.layers.1.weight`: shape=torch.Size([256, 256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.bev_encoder.ffn.layers.1.bias`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.aspp.input_conv.0.weight`: shape=torch.Size([64, 256, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.aspp.input_conv.1.weight`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.aspp.input_conv.1.bias`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.aspp.input_conv.1.running_mean`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.aspp.input_conv.1.running_var`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.aspp.input_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.aspp.aspp.aspp1.atrous_conv.weight`: shape=torch.Size([64, 64, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.aspp.aspp.aspp1.bn.weight`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.aspp.aspp.aspp1.bn.bias`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.aspp.aspp.aspp1.bn.running_mean`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.aspp.aspp.aspp1.bn.running_var`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.aspp.aspp.aspp1.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.aspp.aspp.aspp2.atrous_conv.weight`: shape=torch.Size([64, 64, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.aspp.aspp.aspp2.bn.weight`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.aspp.aspp.aspp2.bn.bias`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.aspp.aspp.aspp2.bn.running_mean`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.aspp.aspp.aspp2.bn.running_var`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.aspp.aspp.aspp2.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.aspp.aspp.aspp3.atrous_conv.weight`: shape=torch.Size([64, 64, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.aspp.aspp.aspp3.bn.weight`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.aspp.aspp.aspp3.bn.bias`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.aspp.aspp.aspp3.bn.running_mean`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.aspp.aspp.aspp3.bn.running_var`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.aspp.aspp.aspp3.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.aspp.aspp.aspp4.atrous_conv.weight`: shape=torch.Size([64, 64, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.aspp.aspp.aspp4.bn.weight`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.aspp.aspp.aspp4.bn.bias`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.aspp.aspp.aspp4.bn.running_mean`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.aspp.aspp.aspp4.bn.running_var`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.aspp.aspp.aspp4.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.aspp.aspp.global_avg_pool.1.weight`: shape=torch.Size([64, 64, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.aspp.aspp.global_avg_pool.2.weight`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.aspp.aspp.global_avg_pool.2.bias`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.aspp.aspp.global_avg_pool.2.running_mean`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.aspp.aspp.global_avg_pool.2.running_var`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.aspp.aspp.global_avg_pool.2.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.aspp.aspp.conv1.weight`: shape=torch.Size([64, 320, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.aspp.aspp.bn1.weight`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.aspp.aspp.bn1.bias`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.aspp.aspp.bn1.running_mean`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.aspp.aspp.bn1.running_var`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.aspp.aspp.bn1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.aspp.output_conv.0.weight`: shape=torch.Size([256, 64, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.aspp.output_conv.1.weight`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.aspp.output_conv.1.bias`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.aspp.output_conv.1.running_mean`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.aspp.output_conv.1.running_var`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.aspp.output_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.combine_coeff.weight`: shape=torch.Size([1, 256, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.0.combine_coeff.bias`: shape=torch.Size([1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.1.input_conv.0.weight`: shape=torch.Size([256, 256, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.1.input_conv.1.weight`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.1.input_conv.1.bias`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.1.input_conv.1.running_mean`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.1.input_conv.1.running_var`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.1.input_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.1.bev_encoder.norm1.weight`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.1.bev_encoder.norm1.bias`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.1.bev_encoder.attn.w_msa.relative_position_bias_table`: shape=torch.Size([169, 8]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.1.bev_encoder.attn.w_msa.relative_position_index`: shape=torch.Size([49, 49]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.1.bev_encoder.attn.w_msa.qkv.weight`: shape=torch.Size([768, 256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.1.bev_encoder.attn.w_msa.qkv.bias`: shape=torch.Size([768]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.1.bev_encoder.attn.w_msa.proj.weight`: shape=torch.Size([256, 256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.1.bev_encoder.attn.w_msa.proj.bias`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.1.bev_encoder.norm2.weight`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.1.bev_encoder.norm2.bias`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.1.bev_encoder.ffn.layers.0.0.weight`: shape=torch.Size([256, 256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.1.bev_encoder.ffn.layers.0.0.bias`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.1.bev_encoder.ffn.layers.1.weight`: shape=torch.Size([256, 256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.1.bev_encoder.ffn.layers.1.bias`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.1.aspp.input_conv.0.weight`: shape=torch.Size([64, 256, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.1.aspp.input_conv.1.weight`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.1.aspp.input_conv.1.bias`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.1.aspp.input_conv.1.running_mean`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.1.aspp.input_conv.1.running_var`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.1.aspp.input_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.1.aspp.aspp.aspp1.atrous_conv.weight`: shape=torch.Size([64, 64, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.1.aspp.aspp.aspp1.bn.weight`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.1.aspp.aspp.aspp1.bn.bias`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.1.aspp.aspp.aspp1.bn.running_mean`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.1.aspp.aspp.aspp1.bn.running_var`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.1.aspp.aspp.aspp1.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.1.aspp.aspp.aspp2.atrous_conv.weight`: shape=torch.Size([64, 64, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.1.aspp.aspp.aspp2.bn.weight`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.1.aspp.aspp.aspp2.bn.bias`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.1.aspp.aspp.aspp2.bn.running_mean`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.1.aspp.aspp.aspp2.bn.running_var`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.1.aspp.aspp.aspp2.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.1.aspp.aspp.aspp3.atrous_conv.weight`: shape=torch.Size([64, 64, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.1.aspp.aspp.aspp3.bn.weight`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.1.aspp.aspp.aspp3.bn.bias`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.1.aspp.aspp.aspp3.bn.running_mean`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.1.aspp.aspp.aspp3.bn.running_var`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.1.aspp.aspp.aspp3.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.1.aspp.aspp.aspp4.atrous_conv.weight`: shape=torch.Size([64, 64, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.1.aspp.aspp.aspp4.bn.weight`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.1.aspp.aspp.aspp4.bn.bias`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.1.aspp.aspp.aspp4.bn.running_mean`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.1.aspp.aspp.aspp4.bn.running_var`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.1.aspp.aspp.aspp4.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.1.aspp.aspp.global_avg_pool.1.weight`: shape=torch.Size([64, 64, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.1.aspp.aspp.global_avg_pool.2.weight`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.1.aspp.aspp.global_avg_pool.2.bias`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.1.aspp.aspp.global_avg_pool.2.running_mean`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.1.aspp.aspp.global_avg_pool.2.running_var`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.1.aspp.aspp.global_avg_pool.2.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.1.aspp.aspp.conv1.weight`: shape=torch.Size([64, 320, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.1.aspp.aspp.bn1.weight`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.1.aspp.aspp.bn1.bias`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.1.aspp.aspp.bn1.running_mean`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.1.aspp.aspp.bn1.running_var`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.1.aspp.aspp.bn1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.1.aspp.output_conv.0.weight`: shape=torch.Size([256, 64, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.1.aspp.output_conv.1.weight`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.1.aspp.output_conv.1.bias`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.1.aspp.output_conv.1.running_mean`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.1.aspp.output_conv.1.running_var`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.1.aspp.output_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.1.combine_coeff.weight`: shape=torch.Size([1, 256, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.2.1.combine_coeff.bias`: shape=torch.Size([1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.downsample.0.weight`: shape=torch.Size([512, 256, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.downsample.1.weight`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.downsample.1.bias`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.downsample.1.running_mean`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.downsample.1.running_var`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.downsample.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.input_conv.0.weight`: shape=torch.Size([512, 256, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.input_conv.1.weight`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.input_conv.1.bias`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.input_conv.1.running_mean`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.input_conv.1.running_var`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.input_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.bev_encoder.norm1.weight`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.bev_encoder.norm1.bias`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.bev_encoder.attn.w_msa.relative_position_bias_table`: shape=torch.Size([169, 16]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.bev_encoder.attn.w_msa.relative_position_index`: shape=torch.Size([49, 49]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.bev_encoder.attn.w_msa.qkv.weight`: shape=torch.Size([1536, 512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.bev_encoder.attn.w_msa.qkv.bias`: shape=torch.Size([1536]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.bev_encoder.attn.w_msa.proj.weight`: shape=torch.Size([512, 512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.bev_encoder.attn.w_msa.proj.bias`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.bev_encoder.norm2.weight`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.bev_encoder.norm2.bias`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.bev_encoder.ffn.layers.0.0.weight`: shape=torch.Size([512, 512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.bev_encoder.ffn.layers.0.0.bias`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.bev_encoder.ffn.layers.1.weight`: shape=torch.Size([512, 512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.bev_encoder.ffn.layers.1.bias`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.aspp.input_conv.0.weight`: shape=torch.Size([128, 512, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.aspp.input_conv.1.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.aspp.input_conv.1.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.aspp.input_conv.1.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.aspp.input_conv.1.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.aspp.input_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.aspp.aspp.aspp1.atrous_conv.weight`: shape=torch.Size([128, 128, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.aspp.aspp.aspp1.bn.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.aspp.aspp.aspp1.bn.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.aspp.aspp.aspp1.bn.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.aspp.aspp.aspp1.bn.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.aspp.aspp.aspp1.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.aspp.aspp.aspp2.atrous_conv.weight`: shape=torch.Size([128, 128, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.aspp.aspp.aspp2.bn.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.aspp.aspp.aspp2.bn.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.aspp.aspp.aspp2.bn.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.aspp.aspp.aspp2.bn.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.aspp.aspp.aspp2.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.aspp.aspp.aspp3.atrous_conv.weight`: shape=torch.Size([128, 128, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.aspp.aspp.aspp3.bn.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.aspp.aspp.aspp3.bn.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.aspp.aspp.aspp3.bn.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.aspp.aspp.aspp3.bn.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.aspp.aspp.aspp3.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.aspp.aspp.aspp4.atrous_conv.weight`: shape=torch.Size([128, 128, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.aspp.aspp.aspp4.bn.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.aspp.aspp.aspp4.bn.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.aspp.aspp.aspp4.bn.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.aspp.aspp.aspp4.bn.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.aspp.aspp.aspp4.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.aspp.aspp.global_avg_pool.1.weight`: shape=torch.Size([128, 128, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.aspp.aspp.global_avg_pool.2.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.aspp.aspp.global_avg_pool.2.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.aspp.aspp.global_avg_pool.2.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.aspp.aspp.global_avg_pool.2.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.aspp.aspp.global_avg_pool.2.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.aspp.aspp.conv1.weight`: shape=torch.Size([128, 640, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.aspp.aspp.bn1.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.aspp.aspp.bn1.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.aspp.aspp.bn1.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.aspp.aspp.bn1.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.aspp.aspp.bn1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.aspp.output_conv.0.weight`: shape=torch.Size([512, 128, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.aspp.output_conv.1.weight`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.aspp.output_conv.1.bias`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.aspp.output_conv.1.running_mean`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.aspp.output_conv.1.running_var`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.aspp.output_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.combine_coeff.weight`: shape=torch.Size([1, 512, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.0.combine_coeff.bias`: shape=torch.Size([1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.1.input_conv.0.weight`: shape=torch.Size([512, 512, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.1.input_conv.1.weight`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.1.input_conv.1.bias`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.1.input_conv.1.running_mean`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.1.input_conv.1.running_var`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.1.input_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.1.bev_encoder.norm1.weight`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.1.bev_encoder.norm1.bias`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.1.bev_encoder.attn.w_msa.relative_position_bias_table`: shape=torch.Size([169, 16]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.1.bev_encoder.attn.w_msa.relative_position_index`: shape=torch.Size([49, 49]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.1.bev_encoder.attn.w_msa.qkv.weight`: shape=torch.Size([1536, 512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.1.bev_encoder.attn.w_msa.qkv.bias`: shape=torch.Size([1536]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.1.bev_encoder.attn.w_msa.proj.weight`: shape=torch.Size([512, 512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.1.bev_encoder.attn.w_msa.proj.bias`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.1.bev_encoder.norm2.weight`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.1.bev_encoder.norm2.bias`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.1.bev_encoder.ffn.layers.0.0.weight`: shape=torch.Size([512, 512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.1.bev_encoder.ffn.layers.0.0.bias`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.1.bev_encoder.ffn.layers.1.weight`: shape=torch.Size([512, 512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.1.bev_encoder.ffn.layers.1.bias`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.1.aspp.input_conv.0.weight`: shape=torch.Size([128, 512, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.1.aspp.input_conv.1.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.1.aspp.input_conv.1.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.1.aspp.input_conv.1.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.1.aspp.input_conv.1.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.1.aspp.input_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.1.aspp.aspp.aspp1.atrous_conv.weight`: shape=torch.Size([128, 128, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.1.aspp.aspp.aspp1.bn.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.1.aspp.aspp.aspp1.bn.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.1.aspp.aspp.aspp1.bn.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.1.aspp.aspp.aspp1.bn.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.1.aspp.aspp.aspp1.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.1.aspp.aspp.aspp2.atrous_conv.weight`: shape=torch.Size([128, 128, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.1.aspp.aspp.aspp2.bn.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.1.aspp.aspp.aspp2.bn.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.1.aspp.aspp.aspp2.bn.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.1.aspp.aspp.aspp2.bn.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.1.aspp.aspp.aspp2.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.1.aspp.aspp.aspp3.atrous_conv.weight`: shape=torch.Size([128, 128, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.1.aspp.aspp.aspp3.bn.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.1.aspp.aspp.aspp3.bn.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.1.aspp.aspp.aspp3.bn.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.1.aspp.aspp.aspp3.bn.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.1.aspp.aspp.aspp3.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.1.aspp.aspp.aspp4.atrous_conv.weight`: shape=torch.Size([128, 128, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.1.aspp.aspp.aspp4.bn.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.1.aspp.aspp.aspp4.bn.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.1.aspp.aspp.aspp4.bn.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.1.aspp.aspp.aspp4.bn.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.1.aspp.aspp.aspp4.bn.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.1.aspp.aspp.global_avg_pool.1.weight`: shape=torch.Size([128, 128, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.1.aspp.aspp.global_avg_pool.2.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.1.aspp.aspp.global_avg_pool.2.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.1.aspp.aspp.global_avg_pool.2.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.1.aspp.aspp.global_avg_pool.2.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.1.aspp.aspp.global_avg_pool.2.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.1.aspp.aspp.conv1.weight`: shape=torch.Size([128, 640, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.1.aspp.aspp.bn1.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.1.aspp.aspp.bn1.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.1.aspp.aspp.bn1.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.1.aspp.aspp.bn1.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.1.aspp.aspp.bn1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.1.aspp.output_conv.0.weight`: shape=torch.Size([512, 128, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.1.aspp.output_conv.1.weight`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.1.aspp.output_conv.1.bias`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.1.aspp.output_conv.1.running_mean`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.1.aspp.output_conv.1.running_var`: shape=torch.Size([512]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.1.aspp.output_conv.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.1.combine_coeff.weight`: shape=torch.Size([1, 512, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.img_bev_encoder_backbone_xz.layers.3.1.combine_coeff.bias`: shape=torch.Size([1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.deblocks.0.0.weight`: shape=torch.Size([256, 512, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.deblocks.0.1.weight`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.deblocks.0.1.bias`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.deblocks.0.1.running_mean`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.deblocks.0.1.running_var`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.deblocks.0.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.deblocks.1.0.weight`: shape=torch.Size([256, 256, 2, 2, 2]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.deblocks.1.1.weight`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.deblocks.1.1.bias`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.deblocks.1.1.running_mean`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.deblocks.1.1.running_var`: shape=torch.Size([256]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.deblocks.1.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.deblocks.2.0.weight`: shape=torch.Size([128, 256, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.deblocks.2.1.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.deblocks.2.1.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.deblocks.2.1.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.deblocks.2.1.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.deblocks.2.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.deblocks.3.0.weight`: shape=torch.Size([128, 128, 2, 2, 2]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.deblocks.3.1.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.deblocks.3.1.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.deblocks.3.1.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.deblocks.3.1.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.deblocks.3.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.deblocks.4.0.weight`: shape=torch.Size([128, 128, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.deblocks.4.1.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.deblocks.4.1.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.deblocks.4.1.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.deblocks.4.1.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.deblocks.4.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.deblocks.5.0.weight`: shape=torch.Size([128, 128, 2, 2, 2]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.deblocks.5.1.weight`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.deblocks.5.1.bias`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.deblocks.5.1.running_mean`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.deblocks.5.1.running_var`: shape=torch.Size([128]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.deblocks.5.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.deblocks.6.0.weight`: shape=torch.Size([64, 128, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.deblocks.6.1.weight`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.deblocks.6.1.bias`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.deblocks.6.1.running_mean`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.deblocks.6.1.running_var`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.deblocks.6.1.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.occ.0.weight`: shape=torch.Size([3, 256, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.occ.1.weight`: shape=torch.Size([3, 128, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.occ.2.weight`: shape=torch.Size([3, 128, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.occ.3.weight`: shape=torch.Size([3, 64, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.sdf.0.weight`: shape=torch.Size([4, 256, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.sdf.1.weight`: shape=torch.Size([4, 128, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.sdf.2.weight`: shape=torch.Size([4, 128, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.sdf.3.weight`: shape=torch.Size([4, 64, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.ray_sampler.rays`: shape=torch.Size([74, 112, 2]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.ray_sampler_opendata.rays`: shape=torch.Size([74, 112, 2]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.render_model.field.laplace_density.beta_min`: shape=torch.Size([1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.render_model.field.laplace_density.beta`: shape=torch.Size([1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.render_model.field.deviation_network.variance`: shape=torch.Size([1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.pre_vq_conv.conv.weight`: shape=torch.Size([4, 320, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.pre_vq_conv.conv.bias`: shape=torch.Size([4]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.convs.0.conv.weight`: shape=torch.Size([320, 320, 4, 4, 4]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.convs.0.conv.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.conv_last.conv.weight`: shape=torch.Size([320, 320, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.conv_last.conv.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.0.block.0.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.0.block.0.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.0.block.0.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.0.block.0.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.0.block.0.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.0.block.2.conv.weight`: shape=torch.Size([160, 320, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.0.block.3.weight`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.0.block.3.bias`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.0.block.3.running_mean`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.0.block.3.running_var`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.0.block.3.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.0.block.5.conv.weight`: shape=torch.Size([320, 160, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.0.block.6.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.0.block.6.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.0.block.6.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.0.block.6.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.0.block.6.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.0.block.8.attn_w.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.0.block.8.attn_w.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.0.block.8.attn_w.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.0.block.8.attn_w.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.0.block.8.attn_w.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.0.block.8.attn_h.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.0.block.8.attn_h.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.0.block.8.attn_h.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.0.block.8.attn_h.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.0.block.8.attn_h.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.0.block.8.attn_t.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.0.block.8.attn_t.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.0.block.8.attn_t.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.0.block.8.attn_t.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.0.block.8.attn_t.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.1.block.0.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.1.block.0.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.1.block.0.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.1.block.0.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.1.block.0.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.1.block.2.conv.weight`: shape=torch.Size([160, 320, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.1.block.3.weight`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.1.block.3.bias`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.1.block.3.running_mean`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.1.block.3.running_var`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.1.block.3.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.1.block.5.conv.weight`: shape=torch.Size([320, 160, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.1.block.6.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.1.block.6.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.1.block.6.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.1.block.6.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.1.block.6.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.1.block.8.attn_w.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.1.block.8.attn_w.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.1.block.8.attn_w.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.1.block.8.attn_w.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.1.block.8.attn_w.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.1.block.8.attn_h.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.1.block.8.attn_h.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.1.block.8.attn_h.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.1.block.8.attn_h.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.1.block.8.attn_h.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.1.block.8.attn_t.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.1.block.8.attn_t.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.1.block.8.attn_t.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.1.block.8.attn_t.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.1.block.8.attn_t.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.2.block.0.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.2.block.0.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.2.block.0.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.2.block.0.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.2.block.0.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.2.block.2.conv.weight`: shape=torch.Size([160, 320, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.2.block.3.weight`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.2.block.3.bias`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.2.block.3.running_mean`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.2.block.3.running_var`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.2.block.3.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.2.block.5.conv.weight`: shape=torch.Size([320, 160, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.2.block.6.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.2.block.6.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.2.block.6.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.2.block.6.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.2.block.6.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.2.block.8.attn_w.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.2.block.8.attn_w.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.2.block.8.attn_w.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.2.block.8.attn_w.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.2.block.8.attn_w.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.2.block.8.attn_h.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.2.block.8.attn_h.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.2.block.8.attn_h.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.2.block.8.attn_h.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.2.block.8.attn_h.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.2.block.8.attn_t.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.2.block.8.attn_t.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.2.block.8.attn_t.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.2.block.8.attn_t.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.2.block.8.attn_t.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.3.block.0.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.3.block.0.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.3.block.0.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.3.block.0.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.3.block.0.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.3.block.2.conv.weight`: shape=torch.Size([160, 320, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.3.block.3.weight`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.3.block.3.bias`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.3.block.3.running_mean`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.3.block.3.running_var`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.3.block.3.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.3.block.5.conv.weight`: shape=torch.Size([320, 160, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.3.block.6.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.3.block.6.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.3.block.6.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.3.block.6.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.3.block.6.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.3.block.8.attn_w.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.3.block.8.attn_w.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.3.block.8.attn_w.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.3.block.8.attn_w.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.3.block.8.attn_w.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.3.block.8.attn_h.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.3.block.8.attn_h.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.3.block.8.attn_h.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.3.block.8.attn_h.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.3.block.8.attn_h.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.3.block.8.attn_t.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.3.block.8.attn_t.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.3.block.8.attn_t.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.3.block.8.attn_t.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.3.block.8.attn_t.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.4.block.0.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.4.block.0.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.4.block.0.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.4.block.0.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.4.block.0.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.4.block.2.conv.weight`: shape=torch.Size([160, 320, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.4.block.3.weight`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.4.block.3.bias`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.4.block.3.running_mean`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.4.block.3.running_var`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.4.block.3.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.4.block.5.conv.weight`: shape=torch.Size([320, 160, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.4.block.6.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.4.block.6.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.4.block.6.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.4.block.6.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.4.block.6.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.4.block.8.attn_w.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.4.block.8.attn_w.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.4.block.8.attn_w.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.4.block.8.attn_w.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.4.block.8.attn_w.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.4.block.8.attn_h.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.4.block.8.attn_h.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.4.block.8.attn_h.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.4.block.8.attn_h.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.4.block.8.attn_h.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.4.block.8.attn_t.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.4.block.8.attn_t.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.4.block.8.attn_t.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.4.block.8.attn_t.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.4.block.8.attn_t.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.5.block.0.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.5.block.0.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.5.block.0.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.5.block.0.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.5.block.0.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.5.block.2.conv.weight`: shape=torch.Size([160, 320, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.5.block.3.weight`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.5.block.3.bias`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.5.block.3.running_mean`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.5.block.3.running_var`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.5.block.3.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.5.block.5.conv.weight`: shape=torch.Size([320, 160, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.5.block.6.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.5.block.6.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.5.block.6.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.5.block.6.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.5.block.6.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.5.block.8.attn_w.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.5.block.8.attn_w.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.5.block.8.attn_w.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.5.block.8.attn_w.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.5.block.8.attn_w.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.5.block.8.attn_h.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.5.block.8.attn_h.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.5.block.8.attn_h.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.5.block.8.attn_h.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.5.block.8.attn_h.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.5.block.8.attn_t.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.5.block.8.attn_t.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.5.block.8.attn_t.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.5.block.8.attn_t.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.5.block.8.attn_t.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.6.block.0.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.6.block.0.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.6.block.0.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.6.block.0.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.6.block.0.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.6.block.2.conv.weight`: shape=torch.Size([160, 320, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.6.block.3.weight`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.6.block.3.bias`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.6.block.3.running_mean`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.6.block.3.running_var`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.6.block.3.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.6.block.5.conv.weight`: shape=torch.Size([320, 160, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.6.block.6.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.6.block.6.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.6.block.6.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.6.block.6.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.6.block.6.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.6.block.8.attn_w.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.6.block.8.attn_w.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.6.block.8.attn_w.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.6.block.8.attn_w.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.6.block.8.attn_w.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.6.block.8.attn_h.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.6.block.8.attn_h.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.6.block.8.attn_h.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.6.block.8.attn_h.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.6.block.8.attn_h.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.6.block.8.attn_t.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.6.block.8.attn_t.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.6.block.8.attn_t.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.6.block.8.attn_t.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.6.block.8.attn_t.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.7.block.0.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.7.block.0.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.7.block.0.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.7.block.0.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.7.block.0.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.7.block.2.conv.weight`: shape=torch.Size([160, 320, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.7.block.3.weight`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.7.block.3.bias`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.7.block.3.running_mean`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.7.block.3.running_var`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.7.block.3.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.7.block.5.conv.weight`: shape=torch.Size([320, 160, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.7.block.6.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.7.block.6.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.7.block.6.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.7.block.6.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.7.block.6.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.7.block.8.attn_w.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.7.block.8.attn_w.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.7.block.8.attn_w.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.7.block.8.attn_w.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.7.block.8.attn_w.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.7.block.8.attn_h.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.7.block.8.attn_h.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.7.block.8.attn_h.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.7.block.8.attn_h.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.7.block.8.attn_h.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.7.block.8.attn_t.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.7.block.8.attn_t.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.7.block.8.attn_t.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.7.block.8.attn_t.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.7.block.8.attn_t.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.8.block.0.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.8.block.0.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.8.block.0.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.8.block.0.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.8.block.0.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.8.block.2.conv.weight`: shape=torch.Size([160, 320, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.8.block.3.weight`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.8.block.3.bias`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.8.block.3.running_mean`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.8.block.3.running_var`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.8.block.3.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.8.block.5.conv.weight`: shape=torch.Size([320, 160, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.8.block.6.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.8.block.6.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.8.block.6.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.8.block.6.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.8.block.6.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.8.block.8.attn_w.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.8.block.8.attn_w.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.8.block.8.attn_w.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.8.block.8.attn_w.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.8.block.8.attn_w.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.8.block.8.attn_h.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.8.block.8.attn_h.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.8.block.8.attn_h.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.8.block.8.attn_h.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.8.block.8.attn_h.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.8.block.8.attn_t.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.8.block.8.attn_t.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.8.block.8.attn_t.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.8.block.8.attn_t.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.8.block.8.attn_t.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.9.block.0.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.9.block.0.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.9.block.0.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.9.block.0.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.9.block.0.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.9.block.2.conv.weight`: shape=torch.Size([160, 320, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.9.block.3.weight`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.9.block.3.bias`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.9.block.3.running_mean`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.9.block.3.running_var`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.9.block.3.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.9.block.5.conv.weight`: shape=torch.Size([320, 160, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.9.block.6.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.9.block.6.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.9.block.6.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.9.block.6.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.9.block.6.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.9.block.8.attn_w.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.9.block.8.attn_w.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.9.block.8.attn_w.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.9.block.8.attn_w.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.9.block.8.attn_w.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.9.block.8.attn_h.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.9.block.8.attn_h.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.9.block.8.attn_h.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.9.block.8.attn_h.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.9.block.8.attn_h.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.9.block.8.attn_t.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.9.block.8.attn_t.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.9.block.8.attn_t.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.9.block.8.attn_t.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.9.block.8.attn_t.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.10.block.0.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.10.block.0.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.10.block.0.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.10.block.0.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.10.block.0.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.10.block.2.conv.weight`: shape=torch.Size([160, 320, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.10.block.3.weight`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.10.block.3.bias`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.10.block.3.running_mean`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.10.block.3.running_var`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.10.block.3.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.10.block.5.conv.weight`: shape=torch.Size([320, 160, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.10.block.6.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.10.block.6.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.10.block.6.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.10.block.6.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.10.block.6.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.10.block.8.attn_w.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.10.block.8.attn_w.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.10.block.8.attn_w.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.10.block.8.attn_w.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.10.block.8.attn_w.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.10.block.8.attn_h.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.10.block.8.attn_h.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.10.block.8.attn_h.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.10.block.8.attn_h.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.10.block.8.attn_h.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.10.block.8.attn_t.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.10.block.8.attn_t.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.10.block.8.attn_t.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.10.block.8.attn_t.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.10.block.8.attn_t.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.11.block.0.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.11.block.0.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.11.block.0.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.11.block.0.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.11.block.0.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.11.block.2.conv.weight`: shape=torch.Size([160, 320, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.11.block.3.weight`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.11.block.3.bias`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.11.block.3.running_mean`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.11.block.3.running_var`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.11.block.3.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.11.block.5.conv.weight`: shape=torch.Size([320, 160, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.11.block.6.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.11.block.6.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.11.block.6.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.11.block.6.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.11.block.6.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.11.block.8.attn_w.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.11.block.8.attn_w.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.11.block.8.attn_w.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.11.block.8.attn_w.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.11.block.8.attn_w.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.11.block.8.attn_h.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.11.block.8.attn_h.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.11.block.8.attn_h.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.11.block.8.attn_h.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.11.block.8.attn_h.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.11.block.8.attn_t.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.11.block.8.attn_t.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.11.block.8.attn_t.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.11.block.8.attn_t.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.11.block.8.attn_t.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.12.block.0.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.12.block.0.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.12.block.0.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.12.block.0.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.12.block.0.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.12.block.2.conv.weight`: shape=torch.Size([160, 320, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.12.block.3.weight`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.12.block.3.bias`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.12.block.3.running_mean`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.12.block.3.running_var`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.12.block.3.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.12.block.5.conv.weight`: shape=torch.Size([320, 160, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.12.block.6.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.12.block.6.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.12.block.6.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.12.block.6.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.12.block.6.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.12.block.8.attn_w.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.12.block.8.attn_w.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.12.block.8.attn_w.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.12.block.8.attn_w.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.12.block.8.attn_w.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.12.block.8.attn_h.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.12.block.8.attn_h.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.12.block.8.attn_h.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.12.block.8.attn_h.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.12.block.8.attn_h.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.12.block.8.attn_t.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.12.block.8.attn_t.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.12.block.8.attn_t.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.12.block.8.attn_t.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.12.block.8.attn_t.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.13.block.0.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.13.block.0.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.13.block.0.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.13.block.0.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.13.block.0.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.13.block.2.conv.weight`: shape=torch.Size([160, 320, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.13.block.3.weight`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.13.block.3.bias`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.13.block.3.running_mean`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.13.block.3.running_var`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.13.block.3.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.13.block.5.conv.weight`: shape=torch.Size([320, 160, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.13.block.6.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.13.block.6.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.13.block.6.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.13.block.6.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.13.block.6.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.13.block.8.attn_w.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.13.block.8.attn_w.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.13.block.8.attn_w.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.13.block.8.attn_w.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.13.block.8.attn_w.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.13.block.8.attn_h.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.13.block.8.attn_h.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.13.block.8.attn_h.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.13.block.8.attn_h.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.13.block.8.attn_h.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.13.block.8.attn_t.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.13.block.8.attn_t.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.13.block.8.attn_t.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.13.block.8.attn_t.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.13.block.8.attn_t.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.14.block.0.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.14.block.0.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.14.block.0.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.14.block.0.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.14.block.0.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.14.block.2.conv.weight`: shape=torch.Size([160, 320, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.14.block.3.weight`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.14.block.3.bias`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.14.block.3.running_mean`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.14.block.3.running_var`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.14.block.3.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.14.block.5.conv.weight`: shape=torch.Size([320, 160, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.14.block.6.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.14.block.6.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.14.block.6.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.14.block.6.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.14.block.6.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.14.block.8.attn_w.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.14.block.8.attn_w.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.14.block.8.attn_w.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.14.block.8.attn_w.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.14.block.8.attn_w.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.14.block.8.attn_h.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.14.block.8.attn_h.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.14.block.8.attn_h.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.14.block.8.attn_h.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.14.block.8.attn_h.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.14.block.8.attn_t.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.14.block.8.attn_t.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.14.block.8.attn_t.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.14.block.8.attn_t.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.14.block.8.attn_t.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.15.block.0.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.15.block.0.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.15.block.0.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.15.block.0.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.15.block.0.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.15.block.2.conv.weight`: shape=torch.Size([160, 320, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.15.block.3.weight`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.15.block.3.bias`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.15.block.3.running_mean`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.15.block.3.running_var`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.15.block.3.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.15.block.5.conv.weight`: shape=torch.Size([320, 160, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.15.block.6.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.15.block.6.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.15.block.6.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.15.block.6.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.15.block.6.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.15.block.8.attn_w.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.15.block.8.attn_w.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.15.block.8.attn_w.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.15.block.8.attn_w.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.15.block.8.attn_w.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.15.block.8.attn_h.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.15.block.8.attn_h.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.15.block.8.attn_h.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.15.block.8.attn_h.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.15.block.8.attn_h.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.15.block.8.attn_t.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.15.block.8.attn_t.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.15.block.8.attn_t.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.15.block.8.attn_t.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.15.block.8.attn_t.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.16.block.0.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.16.block.0.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.16.block.0.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.16.block.0.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.16.block.0.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.16.block.2.conv.weight`: shape=torch.Size([160, 320, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.16.block.3.weight`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.16.block.3.bias`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.16.block.3.running_mean`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.16.block.3.running_var`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.16.block.3.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.16.block.5.conv.weight`: shape=torch.Size([320, 160, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.16.block.6.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.16.block.6.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.16.block.6.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.16.block.6.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.16.block.6.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.16.block.8.attn_w.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.16.block.8.attn_w.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.16.block.8.attn_w.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.16.block.8.attn_w.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.16.block.8.attn_w.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.16.block.8.attn_h.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.16.block.8.attn_h.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.16.block.8.attn_h.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.16.block.8.attn_h.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.16.block.8.attn_h.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.16.block.8.attn_t.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.16.block.8.attn_t.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.16.block.8.attn_t.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.16.block.8.attn_t.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.16.block.8.attn_t.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.17.block.0.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.17.block.0.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.17.block.0.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.17.block.0.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.17.block.0.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.17.block.2.conv.weight`: shape=torch.Size([160, 320, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.17.block.3.weight`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.17.block.3.bias`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.17.block.3.running_mean`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.17.block.3.running_var`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.17.block.3.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.17.block.5.conv.weight`: shape=torch.Size([320, 160, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.17.block.6.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.17.block.6.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.17.block.6.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.17.block.6.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.17.block.6.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.17.block.8.attn_w.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.17.block.8.attn_w.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.17.block.8.attn_w.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.17.block.8.attn_w.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.17.block.8.attn_w.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.17.block.8.attn_h.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.17.block.8.attn_h.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.17.block.8.attn_h.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.17.block.8.attn_h.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.17.block.8.attn_h.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.17.block.8.attn_t.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.17.block.8.attn_t.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.17.block.8.attn_t.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.17.block.8.attn_t.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.17.block.8.attn_t.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.18.block.0.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.18.block.0.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.18.block.0.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.18.block.0.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.18.block.0.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.18.block.2.conv.weight`: shape=torch.Size([160, 320, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.18.block.3.weight`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.18.block.3.bias`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.18.block.3.running_mean`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.18.block.3.running_var`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.18.block.3.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.18.block.5.conv.weight`: shape=torch.Size([320, 160, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.18.block.6.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.18.block.6.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.18.block.6.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.18.block.6.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.18.block.6.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.18.block.8.attn_w.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.18.block.8.attn_w.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.18.block.8.attn_w.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.18.block.8.attn_w.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.18.block.8.attn_w.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.18.block.8.attn_h.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.18.block.8.attn_h.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.18.block.8.attn_h.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.18.block.8.attn_h.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.18.block.8.attn_h.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.18.block.8.attn_t.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.18.block.8.attn_t.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.18.block.8.attn_t.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.18.block.8.attn_t.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.18.block.8.attn_t.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.19.block.0.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.19.block.0.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.19.block.0.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.19.block.0.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.19.block.0.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.19.block.2.conv.weight`: shape=torch.Size([160, 320, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.19.block.3.weight`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.19.block.3.bias`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.19.block.3.running_mean`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.19.block.3.running_var`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.19.block.3.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.19.block.5.conv.weight`: shape=torch.Size([320, 160, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.19.block.6.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.19.block.6.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.19.block.6.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.19.block.6.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.19.block.6.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.19.block.8.attn_w.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.19.block.8.attn_w.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.19.block.8.attn_w.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.19.block.8.attn_w.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.19.block.8.attn_w.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.19.block.8.attn_h.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.19.block.8.attn_h.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.19.block.8.attn_h.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.19.block.8.attn_h.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.19.block.8.attn_h.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.19.block.8.attn_t.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.19.block.8.attn_t.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.19.block.8.attn_t.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.19.block.8.attn_t.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.19.block.8.attn_t.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.20.block.0.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.20.block.0.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.20.block.0.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.20.block.0.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.20.block.0.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.20.block.2.conv.weight`: shape=torch.Size([160, 320, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.20.block.3.weight`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.20.block.3.bias`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.20.block.3.running_mean`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.20.block.3.running_var`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.20.block.3.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.20.block.5.conv.weight`: shape=torch.Size([320, 160, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.20.block.6.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.20.block.6.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.20.block.6.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.20.block.6.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.20.block.6.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.20.block.8.attn_w.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.20.block.8.attn_w.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.20.block.8.attn_w.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.20.block.8.attn_w.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.20.block.8.attn_w.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.20.block.8.attn_h.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.20.block.8.attn_h.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.20.block.8.attn_h.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.20.block.8.attn_h.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.20.block.8.attn_h.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.20.block.8.attn_t.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.20.block.8.attn_t.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.20.block.8.attn_t.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.20.block.8.attn_t.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.20.block.8.attn_t.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.21.block.0.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.21.block.0.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.21.block.0.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.21.block.0.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.21.block.0.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.21.block.2.conv.weight`: shape=torch.Size([160, 320, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.21.block.3.weight`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.21.block.3.bias`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.21.block.3.running_mean`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.21.block.3.running_var`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.21.block.3.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.21.block.5.conv.weight`: shape=torch.Size([320, 160, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.21.block.6.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.21.block.6.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.21.block.6.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.21.block.6.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.21.block.6.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.21.block.8.attn_w.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.21.block.8.attn_w.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.21.block.8.attn_w.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.21.block.8.attn_w.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.21.block.8.attn_w.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.21.block.8.attn_h.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.21.block.8.attn_h.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.21.block.8.attn_h.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.21.block.8.attn_h.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.21.block.8.attn_h.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.21.block.8.attn_t.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.21.block.8.attn_t.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.21.block.8.attn_t.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.21.block.8.attn_t.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.21.block.8.attn_t.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.22.block.0.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.22.block.0.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.22.block.0.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.22.block.0.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.22.block.0.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.22.block.2.conv.weight`: shape=torch.Size([160, 320, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.22.block.3.weight`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.22.block.3.bias`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.22.block.3.running_mean`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.22.block.3.running_var`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.22.block.3.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.22.block.5.conv.weight`: shape=torch.Size([320, 160, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.22.block.6.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.22.block.6.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.22.block.6.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.22.block.6.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.22.block.6.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.22.block.8.attn_w.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.22.block.8.attn_w.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.22.block.8.attn_w.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.22.block.8.attn_w.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.22.block.8.attn_w.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.22.block.8.attn_h.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.22.block.8.attn_h.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.22.block.8.attn_h.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.22.block.8.attn_h.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.22.block.8.attn_h.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.22.block.8.attn_t.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.22.block.8.attn_t.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.22.block.8.attn_t.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.22.block.8.attn_t.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.22.block.8.attn_t.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.23.block.0.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.23.block.0.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.23.block.0.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.23.block.0.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.23.block.0.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.23.block.2.conv.weight`: shape=torch.Size([160, 320, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.23.block.3.weight`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.23.block.3.bias`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.23.block.3.running_mean`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.23.block.3.running_var`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.23.block.3.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.23.block.5.conv.weight`: shape=torch.Size([320, 160, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.23.block.6.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.23.block.6.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.23.block.6.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.23.block.6.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.23.block.6.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.23.block.8.attn_w.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.23.block.8.attn_w.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.23.block.8.attn_w.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.23.block.8.attn_w.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.23.block.8.attn_w.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.23.block.8.attn_h.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.23.block.8.attn_h.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.23.block.8.attn_h.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.23.block.8.attn_h.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.23.block.8.attn_h.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.23.block.8.attn_t.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.23.block.8.attn_t.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.23.block.8.attn_t.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.23.block.8.attn_t.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.23.block.8.attn_t.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.24.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.24.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.24.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.24.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.encoder_gpt.res_stack.24.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.post_vq_conv.conv.weight`: shape=torch.Size([320, 4, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.post_vq_conv.conv.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.0.block.0.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.0.block.0.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.0.block.0.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.0.block.0.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.0.block.0.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.0.block.2.conv.weight`: shape=torch.Size([160, 320, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.0.block.3.weight`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.0.block.3.bias`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.0.block.3.running_mean`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.0.block.3.running_var`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.0.block.3.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.0.block.5.conv.weight`: shape=torch.Size([320, 160, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.0.block.6.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.0.block.6.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.0.block.6.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.0.block.6.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.0.block.6.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.0.block.8.attn_w.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.0.block.8.attn_w.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.0.block.8.attn_w.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.0.block.8.attn_w.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.0.block.8.attn_w.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.0.block.8.attn_h.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.0.block.8.attn_h.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.0.block.8.attn_h.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.0.block.8.attn_h.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.0.block.8.attn_h.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.0.block.8.attn_t.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.0.block.8.attn_t.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.0.block.8.attn_t.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.0.block.8.attn_t.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.0.block.8.attn_t.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.1.block.0.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.1.block.0.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.1.block.0.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.1.block.0.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.1.block.0.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.1.block.2.conv.weight`: shape=torch.Size([160, 320, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.1.block.3.weight`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.1.block.3.bias`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.1.block.3.running_mean`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.1.block.3.running_var`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.1.block.3.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.1.block.5.conv.weight`: shape=torch.Size([320, 160, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.1.block.6.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.1.block.6.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.1.block.6.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.1.block.6.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.1.block.6.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.1.block.8.attn_w.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.1.block.8.attn_w.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.1.block.8.attn_w.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.1.block.8.attn_w.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.1.block.8.attn_w.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.1.block.8.attn_h.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.1.block.8.attn_h.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.1.block.8.attn_h.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.1.block.8.attn_h.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.1.block.8.attn_h.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.1.block.8.attn_t.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.1.block.8.attn_t.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.1.block.8.attn_t.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.1.block.8.attn_t.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.1.block.8.attn_t.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.2.block.0.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.2.block.0.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.2.block.0.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.2.block.0.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.2.block.0.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.2.block.2.conv.weight`: shape=torch.Size([160, 320, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.2.block.3.weight`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.2.block.3.bias`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.2.block.3.running_mean`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.2.block.3.running_var`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.2.block.3.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.2.block.5.conv.weight`: shape=torch.Size([320, 160, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.2.block.6.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.2.block.6.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.2.block.6.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.2.block.6.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.2.block.6.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.2.block.8.attn_w.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.2.block.8.attn_w.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.2.block.8.attn_w.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.2.block.8.attn_w.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.2.block.8.attn_w.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.2.block.8.attn_h.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.2.block.8.attn_h.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.2.block.8.attn_h.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.2.block.8.attn_h.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.2.block.8.attn_h.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.2.block.8.attn_t.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.2.block.8.attn_t.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.2.block.8.attn_t.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.2.block.8.attn_t.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.2.block.8.attn_t.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.3.block.0.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.3.block.0.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.3.block.0.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.3.block.0.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.3.block.0.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.3.block.2.conv.weight`: shape=torch.Size([160, 320, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.3.block.3.weight`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.3.block.3.bias`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.3.block.3.running_mean`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.3.block.3.running_var`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.3.block.3.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.3.block.5.conv.weight`: shape=torch.Size([320, 160, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.3.block.6.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.3.block.6.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.3.block.6.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.3.block.6.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.3.block.6.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.3.block.8.attn_w.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.3.block.8.attn_w.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.3.block.8.attn_w.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.3.block.8.attn_w.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.3.block.8.attn_w.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.3.block.8.attn_h.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.3.block.8.attn_h.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.3.block.8.attn_h.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.3.block.8.attn_h.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.3.block.8.attn_h.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.3.block.8.attn_t.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.3.block.8.attn_t.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.3.block.8.attn_t.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.3.block.8.attn_t.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.3.block.8.attn_t.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.4.block.0.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.4.block.0.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.4.block.0.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.4.block.0.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.4.block.0.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.4.block.2.conv.weight`: shape=torch.Size([160, 320, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.4.block.3.weight`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.4.block.3.bias`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.4.block.3.running_mean`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.4.block.3.running_var`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.4.block.3.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.4.block.5.conv.weight`: shape=torch.Size([320, 160, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.4.block.6.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.4.block.6.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.4.block.6.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.4.block.6.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.4.block.6.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.4.block.8.attn_w.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.4.block.8.attn_w.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.4.block.8.attn_w.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.4.block.8.attn_w.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.4.block.8.attn_w.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.4.block.8.attn_h.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.4.block.8.attn_h.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.4.block.8.attn_h.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.4.block.8.attn_h.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.4.block.8.attn_h.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.4.block.8.attn_t.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.4.block.8.attn_t.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.4.block.8.attn_t.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.4.block.8.attn_t.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.4.block.8.attn_t.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.5.block.0.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.5.block.0.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.5.block.0.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.5.block.0.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.5.block.0.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.5.block.2.conv.weight`: shape=torch.Size([160, 320, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.5.block.3.weight`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.5.block.3.bias`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.5.block.3.running_mean`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.5.block.3.running_var`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.5.block.3.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.5.block.5.conv.weight`: shape=torch.Size([320, 160, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.5.block.6.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.5.block.6.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.5.block.6.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.5.block.6.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.5.block.6.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.5.block.8.attn_w.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.5.block.8.attn_w.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.5.block.8.attn_w.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.5.block.8.attn_w.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.5.block.8.attn_w.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.5.block.8.attn_h.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.5.block.8.attn_h.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.5.block.8.attn_h.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.5.block.8.attn_h.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.5.block.8.attn_h.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.5.block.8.attn_t.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.5.block.8.attn_t.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.5.block.8.attn_t.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.5.block.8.attn_t.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.5.block.8.attn_t.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.6.block.0.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.6.block.0.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.6.block.0.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.6.block.0.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.6.block.0.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.6.block.2.conv.weight`: shape=torch.Size([160, 320, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.6.block.3.weight`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.6.block.3.bias`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.6.block.3.running_mean`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.6.block.3.running_var`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.6.block.3.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.6.block.5.conv.weight`: shape=torch.Size([320, 160, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.6.block.6.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.6.block.6.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.6.block.6.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.6.block.6.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.6.block.6.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.6.block.8.attn_w.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.6.block.8.attn_w.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.6.block.8.attn_w.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.6.block.8.attn_w.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.6.block.8.attn_w.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.6.block.8.attn_h.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.6.block.8.attn_h.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.6.block.8.attn_h.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.6.block.8.attn_h.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.6.block.8.attn_h.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.6.block.8.attn_t.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.6.block.8.attn_t.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.6.block.8.attn_t.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.6.block.8.attn_t.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.6.block.8.attn_t.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.7.block.0.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.7.block.0.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.7.block.0.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.7.block.0.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.7.block.0.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.7.block.2.conv.weight`: shape=torch.Size([160, 320, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.7.block.3.weight`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.7.block.3.bias`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.7.block.3.running_mean`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.7.block.3.running_var`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.7.block.3.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.7.block.5.conv.weight`: shape=torch.Size([320, 160, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.7.block.6.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.7.block.6.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.7.block.6.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.7.block.6.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.7.block.6.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.7.block.8.attn_w.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.7.block.8.attn_w.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.7.block.8.attn_w.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.7.block.8.attn_w.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.7.block.8.attn_w.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.7.block.8.attn_h.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.7.block.8.attn_h.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.7.block.8.attn_h.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.7.block.8.attn_h.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.7.block.8.attn_h.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.7.block.8.attn_t.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.7.block.8.attn_t.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.7.block.8.attn_t.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.7.block.8.attn_t.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.7.block.8.attn_t.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.8.block.0.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.8.block.0.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.8.block.0.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.8.block.0.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.8.block.0.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.8.block.2.conv.weight`: shape=torch.Size([160, 320, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.8.block.3.weight`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.8.block.3.bias`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.8.block.3.running_mean`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.8.block.3.running_var`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.8.block.3.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.8.block.5.conv.weight`: shape=torch.Size([320, 160, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.8.block.6.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.8.block.6.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.8.block.6.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.8.block.6.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.8.block.6.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.8.block.8.attn_w.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.8.block.8.attn_w.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.8.block.8.attn_w.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.8.block.8.attn_w.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.8.block.8.attn_w.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.8.block.8.attn_h.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.8.block.8.attn_h.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.8.block.8.attn_h.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.8.block.8.attn_h.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.8.block.8.attn_h.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.8.block.8.attn_t.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.8.block.8.attn_t.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.8.block.8.attn_t.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.8.block.8.attn_t.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.8.block.8.attn_t.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.9.block.0.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.9.block.0.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.9.block.0.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.9.block.0.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.9.block.0.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.9.block.2.conv.weight`: shape=torch.Size([160, 320, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.9.block.3.weight`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.9.block.3.bias`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.9.block.3.running_mean`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.9.block.3.running_var`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.9.block.3.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.9.block.5.conv.weight`: shape=torch.Size([320, 160, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.9.block.6.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.9.block.6.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.9.block.6.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.9.block.6.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.9.block.6.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.9.block.8.attn_w.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.9.block.8.attn_w.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.9.block.8.attn_w.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.9.block.8.attn_w.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.9.block.8.attn_w.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.9.block.8.attn_h.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.9.block.8.attn_h.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.9.block.8.attn_h.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.9.block.8.attn_h.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.9.block.8.attn_h.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.9.block.8.attn_t.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.9.block.8.attn_t.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.9.block.8.attn_t.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.9.block.8.attn_t.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.9.block.8.attn_t.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.10.block.0.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.10.block.0.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.10.block.0.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.10.block.0.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.10.block.0.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.10.block.2.conv.weight`: shape=torch.Size([160, 320, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.10.block.3.weight`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.10.block.3.bias`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.10.block.3.running_mean`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.10.block.3.running_var`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.10.block.3.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.10.block.5.conv.weight`: shape=torch.Size([320, 160, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.10.block.6.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.10.block.6.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.10.block.6.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.10.block.6.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.10.block.6.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.10.block.8.attn_w.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.10.block.8.attn_w.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.10.block.8.attn_w.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.10.block.8.attn_w.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.10.block.8.attn_w.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.10.block.8.attn_h.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.10.block.8.attn_h.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.10.block.8.attn_h.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.10.block.8.attn_h.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.10.block.8.attn_h.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.10.block.8.attn_t.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.10.block.8.attn_t.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.10.block.8.attn_t.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.10.block.8.attn_t.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.10.block.8.attn_t.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.11.block.0.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.11.block.0.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.11.block.0.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.11.block.0.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.11.block.0.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.11.block.2.conv.weight`: shape=torch.Size([160, 320, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.11.block.3.weight`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.11.block.3.bias`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.11.block.3.running_mean`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.11.block.3.running_var`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.11.block.3.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.11.block.5.conv.weight`: shape=torch.Size([320, 160, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.11.block.6.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.11.block.6.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.11.block.6.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.11.block.6.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.11.block.6.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.11.block.8.attn_w.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.11.block.8.attn_w.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.11.block.8.attn_w.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.11.block.8.attn_w.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.11.block.8.attn_w.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.11.block.8.attn_h.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.11.block.8.attn_h.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.11.block.8.attn_h.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.11.block.8.attn_h.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.11.block.8.attn_h.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.11.block.8.attn_t.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.11.block.8.attn_t.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.11.block.8.attn_t.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.11.block.8.attn_t.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.11.block.8.attn_t.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.12.block.0.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.12.block.0.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.12.block.0.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.12.block.0.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.12.block.0.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.12.block.2.conv.weight`: shape=torch.Size([160, 320, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.12.block.3.weight`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.12.block.3.bias`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.12.block.3.running_mean`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.12.block.3.running_var`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.12.block.3.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.12.block.5.conv.weight`: shape=torch.Size([320, 160, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.12.block.6.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.12.block.6.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.12.block.6.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.12.block.6.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.12.block.6.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.12.block.8.attn_w.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.12.block.8.attn_w.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.12.block.8.attn_w.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.12.block.8.attn_w.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.12.block.8.attn_w.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.12.block.8.attn_h.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.12.block.8.attn_h.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.12.block.8.attn_h.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.12.block.8.attn_h.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.12.block.8.attn_h.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.12.block.8.attn_t.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.12.block.8.attn_t.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.12.block.8.attn_t.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.12.block.8.attn_t.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.12.block.8.attn_t.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.13.block.0.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.13.block.0.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.13.block.0.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.13.block.0.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.13.block.0.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.13.block.2.conv.weight`: shape=torch.Size([160, 320, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.13.block.3.weight`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.13.block.3.bias`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.13.block.3.running_mean`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.13.block.3.running_var`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.13.block.3.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.13.block.5.conv.weight`: shape=torch.Size([320, 160, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.13.block.6.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.13.block.6.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.13.block.6.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.13.block.6.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.13.block.6.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.13.block.8.attn_w.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.13.block.8.attn_w.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.13.block.8.attn_w.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.13.block.8.attn_w.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.13.block.8.attn_w.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.13.block.8.attn_h.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.13.block.8.attn_h.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.13.block.8.attn_h.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.13.block.8.attn_h.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.13.block.8.attn_h.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.13.block.8.attn_t.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.13.block.8.attn_t.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.13.block.8.attn_t.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.13.block.8.attn_t.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.13.block.8.attn_t.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.14.block.0.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.14.block.0.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.14.block.0.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.14.block.0.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.14.block.0.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.14.block.2.conv.weight`: shape=torch.Size([160, 320, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.14.block.3.weight`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.14.block.3.bias`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.14.block.3.running_mean`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.14.block.3.running_var`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.14.block.3.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.14.block.5.conv.weight`: shape=torch.Size([320, 160, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.14.block.6.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.14.block.6.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.14.block.6.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.14.block.6.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.14.block.6.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.14.block.8.attn_w.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.14.block.8.attn_w.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.14.block.8.attn_w.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.14.block.8.attn_w.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.14.block.8.attn_w.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.14.block.8.attn_h.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.14.block.8.attn_h.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.14.block.8.attn_h.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.14.block.8.attn_h.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.14.block.8.attn_h.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.14.block.8.attn_t.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.14.block.8.attn_t.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.14.block.8.attn_t.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.14.block.8.attn_t.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.14.block.8.attn_t.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.15.block.0.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.15.block.0.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.15.block.0.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.15.block.0.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.15.block.0.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.15.block.2.conv.weight`: shape=torch.Size([160, 320, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.15.block.3.weight`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.15.block.3.bias`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.15.block.3.running_mean`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.15.block.3.running_var`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.15.block.3.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.15.block.5.conv.weight`: shape=torch.Size([320, 160, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.15.block.6.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.15.block.6.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.15.block.6.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.15.block.6.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.15.block.6.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.15.block.8.attn_w.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.15.block.8.attn_w.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.15.block.8.attn_w.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.15.block.8.attn_w.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.15.block.8.attn_w.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.15.block.8.attn_h.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.15.block.8.attn_h.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.15.block.8.attn_h.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.15.block.8.attn_h.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.15.block.8.attn_h.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.15.block.8.attn_t.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.15.block.8.attn_t.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.15.block.8.attn_t.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.15.block.8.attn_t.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.15.block.8.attn_t.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.16.block.0.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.16.block.0.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.16.block.0.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.16.block.0.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.16.block.0.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.16.block.2.conv.weight`: shape=torch.Size([160, 320, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.16.block.3.weight`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.16.block.3.bias`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.16.block.3.running_mean`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.16.block.3.running_var`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.16.block.3.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.16.block.5.conv.weight`: shape=torch.Size([320, 160, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.16.block.6.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.16.block.6.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.16.block.6.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.16.block.6.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.16.block.6.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.16.block.8.attn_w.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.16.block.8.attn_w.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.16.block.8.attn_w.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.16.block.8.attn_w.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.16.block.8.attn_w.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.16.block.8.attn_h.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.16.block.8.attn_h.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.16.block.8.attn_h.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.16.block.8.attn_h.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.16.block.8.attn_h.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.16.block.8.attn_t.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.16.block.8.attn_t.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.16.block.8.attn_t.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.16.block.8.attn_t.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.16.block.8.attn_t.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.17.block.0.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.17.block.0.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.17.block.0.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.17.block.0.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.17.block.0.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.17.block.2.conv.weight`: shape=torch.Size([160, 320, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.17.block.3.weight`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.17.block.3.bias`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.17.block.3.running_mean`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.17.block.3.running_var`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.17.block.3.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.17.block.5.conv.weight`: shape=torch.Size([320, 160, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.17.block.6.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.17.block.6.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.17.block.6.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.17.block.6.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.17.block.6.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.17.block.8.attn_w.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.17.block.8.attn_w.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.17.block.8.attn_w.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.17.block.8.attn_w.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.17.block.8.attn_w.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.17.block.8.attn_h.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.17.block.8.attn_h.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.17.block.8.attn_h.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.17.block.8.attn_h.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.17.block.8.attn_h.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.17.block.8.attn_t.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.17.block.8.attn_t.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.17.block.8.attn_t.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.17.block.8.attn_t.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.17.block.8.attn_t.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.18.block.0.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.18.block.0.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.18.block.0.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.18.block.0.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.18.block.0.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.18.block.2.conv.weight`: shape=torch.Size([160, 320, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.18.block.3.weight`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.18.block.3.bias`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.18.block.3.running_mean`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.18.block.3.running_var`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.18.block.3.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.18.block.5.conv.weight`: shape=torch.Size([320, 160, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.18.block.6.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.18.block.6.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.18.block.6.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.18.block.6.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.18.block.6.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.18.block.8.attn_w.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.18.block.8.attn_w.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.18.block.8.attn_w.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.18.block.8.attn_w.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.18.block.8.attn_w.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.18.block.8.attn_h.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.18.block.8.attn_h.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.18.block.8.attn_h.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.18.block.8.attn_h.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.18.block.8.attn_h.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.18.block.8.attn_t.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.18.block.8.attn_t.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.18.block.8.attn_t.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.18.block.8.attn_t.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.18.block.8.attn_t.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.19.block.0.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.19.block.0.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.19.block.0.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.19.block.0.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.19.block.0.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.19.block.2.conv.weight`: shape=torch.Size([160, 320, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.19.block.3.weight`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.19.block.3.bias`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.19.block.3.running_mean`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.19.block.3.running_var`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.19.block.3.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.19.block.5.conv.weight`: shape=torch.Size([320, 160, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.19.block.6.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.19.block.6.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.19.block.6.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.19.block.6.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.19.block.6.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.19.block.8.attn_w.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.19.block.8.attn_w.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.19.block.8.attn_w.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.19.block.8.attn_w.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.19.block.8.attn_w.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.19.block.8.attn_h.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.19.block.8.attn_h.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.19.block.8.attn_h.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.19.block.8.attn_h.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.19.block.8.attn_h.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.19.block.8.attn_t.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.19.block.8.attn_t.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.19.block.8.attn_t.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.19.block.8.attn_t.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.19.block.8.attn_t.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.20.block.0.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.20.block.0.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.20.block.0.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.20.block.0.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.20.block.0.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.20.block.2.conv.weight`: shape=torch.Size([160, 320, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.20.block.3.weight`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.20.block.3.bias`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.20.block.3.running_mean`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.20.block.3.running_var`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.20.block.3.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.20.block.5.conv.weight`: shape=torch.Size([320, 160, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.20.block.6.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.20.block.6.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.20.block.6.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.20.block.6.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.20.block.6.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.20.block.8.attn_w.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.20.block.8.attn_w.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.20.block.8.attn_w.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.20.block.8.attn_w.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.20.block.8.attn_w.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.20.block.8.attn_h.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.20.block.8.attn_h.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.20.block.8.attn_h.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.20.block.8.attn_h.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.20.block.8.attn_h.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.20.block.8.attn_t.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.20.block.8.attn_t.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.20.block.8.attn_t.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.20.block.8.attn_t.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.20.block.8.attn_t.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.21.block.0.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.21.block.0.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.21.block.0.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.21.block.0.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.21.block.0.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.21.block.2.conv.weight`: shape=torch.Size([160, 320, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.21.block.3.weight`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.21.block.3.bias`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.21.block.3.running_mean`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.21.block.3.running_var`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.21.block.3.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.21.block.5.conv.weight`: shape=torch.Size([320, 160, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.21.block.6.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.21.block.6.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.21.block.6.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.21.block.6.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.21.block.6.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.21.block.8.attn_w.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.21.block.8.attn_w.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.21.block.8.attn_w.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.21.block.8.attn_w.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.21.block.8.attn_w.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.21.block.8.attn_h.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.21.block.8.attn_h.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.21.block.8.attn_h.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.21.block.8.attn_h.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.21.block.8.attn_h.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.21.block.8.attn_t.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.21.block.8.attn_t.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.21.block.8.attn_t.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.21.block.8.attn_t.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.21.block.8.attn_t.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.22.block.0.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.22.block.0.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.22.block.0.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.22.block.0.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.22.block.0.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.22.block.2.conv.weight`: shape=torch.Size([160, 320, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.22.block.3.weight`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.22.block.3.bias`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.22.block.3.running_mean`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.22.block.3.running_var`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.22.block.3.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.22.block.5.conv.weight`: shape=torch.Size([320, 160, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.22.block.6.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.22.block.6.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.22.block.6.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.22.block.6.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.22.block.6.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.22.block.8.attn_w.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.22.block.8.attn_w.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.22.block.8.attn_w.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.22.block.8.attn_w.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.22.block.8.attn_w.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.22.block.8.attn_h.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.22.block.8.attn_h.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.22.block.8.attn_h.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.22.block.8.attn_h.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.22.block.8.attn_h.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.22.block.8.attn_t.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.22.block.8.attn_t.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.22.block.8.attn_t.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.22.block.8.attn_t.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.22.block.8.attn_t.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.23.block.0.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.23.block.0.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.23.block.0.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.23.block.0.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.23.block.0.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.23.block.2.conv.weight`: shape=torch.Size([160, 320, 3, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.23.block.3.weight`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.23.block.3.bias`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.23.block.3.running_mean`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.23.block.3.running_var`: shape=torch.Size([160]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.23.block.3.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.23.block.5.conv.weight`: shape=torch.Size([320, 160, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.23.block.6.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.23.block.6.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.23.block.6.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.23.block.6.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.23.block.6.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.23.block.8.attn_w.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.23.block.8.attn_w.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.23.block.8.attn_w.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.23.block.8.attn_w.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.23.block.8.attn_w.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.23.block.8.attn_h.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.23.block.8.attn_h.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.23.block.8.attn_h.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.23.block.8.attn_h.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.23.block.8.attn_h.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.23.block.8.attn_t.w_qs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.23.block.8.attn_t.w_ks.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.23.block.8.attn_t.w_vs.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.23.block.8.attn_t.fc.weight`: shape=torch.Size([320, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.23.block.8.attn_t.fc.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.24.weight`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.24.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.24.running_mean`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.24.running_var`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.res_stack.24.num_batches_tracked`: shape=torch.Size([]), dtype=torch.int64, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.convts.0.convt.weight`: shape=torch.Size([320, 320, 4, 4, 4]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.decoder_gpt.convts.0.convt.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.embedder.weight`: shape=torch.Size([320, 80]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.embedder.bias`: shape=torch.Size([320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.embedder_t.weight`: shape=torch.Size([80, 320]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.embedder_t.bias`: shape=torch.Size([80]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.vqvae.embedding.weight`: shape=torch.Size([320, 4]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.vqvae.quant_conv.weight`: shape=torch.Size([4, 4, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.vqvae.quant_conv.bias`: shape=torch.Size([4]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.vqvae.post_quant_conv.weight`: shape=torch.Size([4, 4, 1, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `pts_bbox_head.vqvae.vqvae.post_quant_conv.bias`: shape=torch.Size([4]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.cls_token`: shape=torch.Size([1, 1, 384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.pos_embed`: shape=torch.Size([1, 1370, 384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.mask_token`: shape=torch.Size([1, 384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.patch_embed.proj.weight`: shape=torch.Size([384, 3, 14, 14]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.patch_embed.proj.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.0.norm1.weight`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.0.norm1.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.0.attn.qkv.weight`: shape=torch.Size([1152, 384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.0.attn.qkv.bias`: shape=torch.Size([1152]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.0.attn.proj.weight`: shape=torch.Size([384, 384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.0.attn.proj.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.0.ls1.gamma`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.0.norm2.weight`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.0.norm2.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.0.mlp.fc1.weight`: shape=torch.Size([1536, 384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.0.mlp.fc1.bias`: shape=torch.Size([1536]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.0.mlp.fc2.weight`: shape=torch.Size([384, 1536]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.0.mlp.fc2.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.0.ls2.gamma`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.1.norm1.weight`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.1.norm1.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.1.attn.qkv.weight`: shape=torch.Size([1152, 384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.1.attn.qkv.bias`: shape=torch.Size([1152]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.1.attn.proj.weight`: shape=torch.Size([384, 384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.1.attn.proj.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.1.ls1.gamma`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.1.norm2.weight`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.1.norm2.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.1.mlp.fc1.weight`: shape=torch.Size([1536, 384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.1.mlp.fc1.bias`: shape=torch.Size([1536]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.1.mlp.fc2.weight`: shape=torch.Size([384, 1536]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.1.mlp.fc2.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.1.ls2.gamma`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.2.norm1.weight`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.2.norm1.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.2.attn.qkv.weight`: shape=torch.Size([1152, 384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.2.attn.qkv.bias`: shape=torch.Size([1152]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.2.attn.proj.weight`: shape=torch.Size([384, 384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.2.attn.proj.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.2.ls1.gamma`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.2.norm2.weight`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.2.norm2.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.2.mlp.fc1.weight`: shape=torch.Size([1536, 384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.2.mlp.fc1.bias`: shape=torch.Size([1536]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.2.mlp.fc2.weight`: shape=torch.Size([384, 1536]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.2.mlp.fc2.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.2.ls2.gamma`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.3.norm1.weight`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.3.norm1.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.3.attn.qkv.weight`: shape=torch.Size([1152, 384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.3.attn.qkv.bias`: shape=torch.Size([1152]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.3.attn.proj.weight`: shape=torch.Size([384, 384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.3.attn.proj.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.3.ls1.gamma`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.3.norm2.weight`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.3.norm2.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.3.mlp.fc1.weight`: shape=torch.Size([1536, 384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.3.mlp.fc1.bias`: shape=torch.Size([1536]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.3.mlp.fc2.weight`: shape=torch.Size([384, 1536]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.3.mlp.fc2.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.3.ls2.gamma`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.4.norm1.weight`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.4.norm1.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.4.attn.qkv.weight`: shape=torch.Size([1152, 384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.4.attn.qkv.bias`: shape=torch.Size([1152]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.4.attn.proj.weight`: shape=torch.Size([384, 384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.4.attn.proj.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.4.ls1.gamma`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.4.norm2.weight`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.4.norm2.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.4.mlp.fc1.weight`: shape=torch.Size([1536, 384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.4.mlp.fc1.bias`: shape=torch.Size([1536]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.4.mlp.fc2.weight`: shape=torch.Size([384, 1536]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.4.mlp.fc2.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.4.ls2.gamma`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.5.norm1.weight`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.5.norm1.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.5.attn.qkv.weight`: shape=torch.Size([1152, 384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.5.attn.qkv.bias`: shape=torch.Size([1152]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.5.attn.proj.weight`: shape=torch.Size([384, 384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.5.attn.proj.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.5.ls1.gamma`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.5.norm2.weight`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.5.norm2.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.5.mlp.fc1.weight`: shape=torch.Size([1536, 384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.5.mlp.fc1.bias`: shape=torch.Size([1536]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.5.mlp.fc2.weight`: shape=torch.Size([384, 1536]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.5.mlp.fc2.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.5.ls2.gamma`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.6.norm1.weight`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.6.norm1.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.6.attn.qkv.weight`: shape=torch.Size([1152, 384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.6.attn.qkv.bias`: shape=torch.Size([1152]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.6.attn.proj.weight`: shape=torch.Size([384, 384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.6.attn.proj.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.6.ls1.gamma`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.6.norm2.weight`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.6.norm2.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.6.mlp.fc1.weight`: shape=torch.Size([1536, 384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.6.mlp.fc1.bias`: shape=torch.Size([1536]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.6.mlp.fc2.weight`: shape=torch.Size([384, 1536]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.6.mlp.fc2.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.6.ls2.gamma`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.7.norm1.weight`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.7.norm1.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.7.attn.qkv.weight`: shape=torch.Size([1152, 384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.7.attn.qkv.bias`: shape=torch.Size([1152]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.7.attn.proj.weight`: shape=torch.Size([384, 384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.7.attn.proj.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.7.ls1.gamma`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.7.norm2.weight`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.7.norm2.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.7.mlp.fc1.weight`: shape=torch.Size([1536, 384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.7.mlp.fc1.bias`: shape=torch.Size([1536]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.7.mlp.fc2.weight`: shape=torch.Size([384, 1536]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.7.mlp.fc2.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.7.ls2.gamma`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.8.norm1.weight`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.8.norm1.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.8.attn.qkv.weight`: shape=torch.Size([1152, 384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.8.attn.qkv.bias`: shape=torch.Size([1152]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.8.attn.proj.weight`: shape=torch.Size([384, 384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.8.attn.proj.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.8.ls1.gamma`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.8.norm2.weight`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.8.norm2.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.8.mlp.fc1.weight`: shape=torch.Size([1536, 384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.8.mlp.fc1.bias`: shape=torch.Size([1536]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.8.mlp.fc2.weight`: shape=torch.Size([384, 1536]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.8.mlp.fc2.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.8.ls2.gamma`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.9.norm1.weight`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.9.norm1.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.9.attn.qkv.weight`: shape=torch.Size([1152, 384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.9.attn.qkv.bias`: shape=torch.Size([1152]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.9.attn.proj.weight`: shape=torch.Size([384, 384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.9.attn.proj.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.9.ls1.gamma`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.9.norm2.weight`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.9.norm2.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.9.mlp.fc1.weight`: shape=torch.Size([1536, 384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.9.mlp.fc1.bias`: shape=torch.Size([1536]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.9.mlp.fc2.weight`: shape=torch.Size([384, 1536]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.9.mlp.fc2.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.9.ls2.gamma`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.10.norm1.weight`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.10.norm1.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.10.attn.qkv.weight`: shape=torch.Size([1152, 384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.10.attn.qkv.bias`: shape=torch.Size([1152]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.10.attn.proj.weight`: shape=torch.Size([384, 384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.10.attn.proj.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.10.ls1.gamma`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.10.norm2.weight`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.10.norm2.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.10.mlp.fc1.weight`: shape=torch.Size([1536, 384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.10.mlp.fc1.bias`: shape=torch.Size([1536]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.10.mlp.fc2.weight`: shape=torch.Size([384, 1536]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.10.mlp.fc2.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.10.ls2.gamma`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.11.norm1.weight`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.11.norm1.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.11.attn.qkv.weight`: shape=torch.Size([1152, 384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.11.attn.qkv.bias`: shape=torch.Size([1152]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.11.attn.proj.weight`: shape=torch.Size([384, 384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.11.attn.proj.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.11.ls1.gamma`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.11.norm2.weight`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.11.norm2.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.11.mlp.fc1.weight`: shape=torch.Size([1536, 384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.11.mlp.fc1.bias`: shape=torch.Size([1536]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.11.mlp.fc2.weight`: shape=torch.Size([384, 1536]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.11.mlp.fc2.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.blocks.11.ls2.gamma`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.norm.weight`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.pretrained.norm.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.depth_head.projects.0.weight`: shape=torch.Size([48, 384, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.depth_head.projects.0.bias`: shape=torch.Size([48]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.depth_head.projects.1.weight`: shape=torch.Size([96, 384, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.depth_head.projects.1.bias`: shape=torch.Size([96]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.depth_head.projects.2.weight`: shape=torch.Size([192, 384, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.depth_head.projects.2.bias`: shape=torch.Size([192]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.depth_head.projects.3.weight`: shape=torch.Size([384, 384, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.depth_head.projects.3.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.depth_head.resize_layers.0.weight`: shape=torch.Size([48, 48, 4, 4]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.depth_head.resize_layers.0.bias`: shape=torch.Size([48]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.depth_head.resize_layers.1.weight`: shape=torch.Size([96, 96, 2, 2]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.depth_head.resize_layers.1.bias`: shape=torch.Size([96]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.depth_head.resize_layers.3.weight`: shape=torch.Size([384, 384, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.depth_head.resize_layers.3.bias`: shape=torch.Size([384]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.depth_head.scratch.layer1_rn.weight`: shape=torch.Size([64, 48, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.depth_head.scratch.layer2_rn.weight`: shape=torch.Size([64, 96, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.depth_head.scratch.layer3_rn.weight`: shape=torch.Size([64, 192, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.depth_head.scratch.layer4_rn.weight`: shape=torch.Size([64, 384, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.depth_head.scratch.refinenet1.out_conv.weight`: shape=torch.Size([64, 64, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.depth_head.scratch.refinenet1.out_conv.bias`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.depth_head.scratch.refinenet1.resConfUnit1.conv1.weight`: shape=torch.Size([64, 64, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.depth_head.scratch.refinenet1.resConfUnit1.conv1.bias`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.depth_head.scratch.refinenet1.resConfUnit1.conv2.weight`: shape=torch.Size([64, 64, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.depth_head.scratch.refinenet1.resConfUnit1.conv2.bias`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.depth_head.scratch.refinenet1.resConfUnit2.conv1.weight`: shape=torch.Size([64, 64, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.depth_head.scratch.refinenet1.resConfUnit2.conv1.bias`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.depth_head.scratch.refinenet1.resConfUnit2.conv2.weight`: shape=torch.Size([64, 64, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.depth_head.scratch.refinenet1.resConfUnit2.conv2.bias`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.depth_head.scratch.refinenet2.out_conv.weight`: shape=torch.Size([64, 64, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.depth_head.scratch.refinenet2.out_conv.bias`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.depth_head.scratch.refinenet2.resConfUnit1.conv1.weight`: shape=torch.Size([64, 64, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.depth_head.scratch.refinenet2.resConfUnit1.conv1.bias`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.depth_head.scratch.refinenet2.resConfUnit1.conv2.weight`: shape=torch.Size([64, 64, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.depth_head.scratch.refinenet2.resConfUnit1.conv2.bias`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.depth_head.scratch.refinenet2.resConfUnit2.conv1.weight`: shape=torch.Size([64, 64, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.depth_head.scratch.refinenet2.resConfUnit2.conv1.bias`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.depth_head.scratch.refinenet2.resConfUnit2.conv2.weight`: shape=torch.Size([64, 64, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.depth_head.scratch.refinenet2.resConfUnit2.conv2.bias`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.depth_head.scratch.refinenet3.out_conv.weight`: shape=torch.Size([64, 64, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.depth_head.scratch.refinenet3.out_conv.bias`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.depth_head.scratch.refinenet3.resConfUnit1.conv1.weight`: shape=torch.Size([64, 64, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.depth_head.scratch.refinenet3.resConfUnit1.conv1.bias`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.depth_head.scratch.refinenet3.resConfUnit1.conv2.weight`: shape=torch.Size([64, 64, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.depth_head.scratch.refinenet3.resConfUnit1.conv2.bias`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.depth_head.scratch.refinenet3.resConfUnit2.conv1.weight`: shape=torch.Size([64, 64, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.depth_head.scratch.refinenet3.resConfUnit2.conv1.bias`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.depth_head.scratch.refinenet3.resConfUnit2.conv2.weight`: shape=torch.Size([64, 64, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.depth_head.scratch.refinenet3.resConfUnit2.conv2.bias`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.depth_head.scratch.refinenet4.out_conv.weight`: shape=torch.Size([64, 64, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.depth_head.scratch.refinenet4.out_conv.bias`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.depth_head.scratch.refinenet4.resConfUnit1.conv1.weight`: shape=torch.Size([64, 64, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.depth_head.scratch.refinenet4.resConfUnit1.conv1.bias`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.depth_head.scratch.refinenet4.resConfUnit1.conv2.weight`: shape=torch.Size([64, 64, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.depth_head.scratch.refinenet4.resConfUnit1.conv2.bias`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.depth_head.scratch.refinenet4.resConfUnit2.conv1.weight`: shape=torch.Size([64, 64, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.depth_head.scratch.refinenet4.resConfUnit2.conv1.bias`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.depth_head.scratch.refinenet4.resConfUnit2.conv2.weight`: shape=torch.Size([64, 64, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.depth_head.scratch.refinenet4.resConfUnit2.conv2.bias`: shape=torch.Size([64]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.depth_head.scratch.output_conv1.weight`: shape=torch.Size([32, 64, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.depth_head.scratch.output_conv1.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.depth_head.scratch.output_conv2.0.weight`: shape=torch.Size([32, 32, 3, 3]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.depth_head.scratch.output_conv2.0.bias`: shape=torch.Size([32]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.depth_head.scratch.output_conv2.2.weight`: shape=torch.Size([1, 32, 1, 1]), dtype=torch.float32, device=cpu
ğŸ”¹ `depthanythingv2.depth_head.scratch.output_conv2.2.bias`: shape=torch.Size([1]), dtype=torch.float32, device=cpu
